{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e89a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "from ase.io import read,write\n",
    "from ovito.io import import_file\n",
    "import WarrenCowleyParameters as wc\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def progress_print(i, total, comment=''):\n",
    "    \"\"\"\n",
    "    Print progress percentage and current file number being processed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        Current iteration index (0-based).\n",
    "    total : int\n",
    "        Total number of items to process.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints progress to stdout with carriage return for dynamic updating.\n",
    "    \"\"\"\n",
    "    progress = (i + 1) / total * 100\n",
    "    print(f'{comment} Progress: {progress:.0f}% \\t Processing File {i+1}/{total}', end='\\r', flush=True)\n",
    "\n",
    "\n",
    "simulation_folder = '/nfshome/winkelmann/CathodeSimulationResults/Lichtenberg_X-mas_25_26'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eff6ee",
   "metadata": {},
   "source": [
    "# find Ovito Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc28a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 ovito files to process.\n",
      "excluded 0 truncated files and their base files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = os.path.join(simulation_folder, '**', '*.XDATCAR')\n",
    "path_all_ovito_files = sorted(glob.glob(pattern, recursive=True))\n",
    "\n",
    "# Find all truncated files and create list of their original files\n",
    "truncated_files = [f for f in path_all_ovito_files if f.endswith('_truncated.XDATCAR')]\n",
    "original_files_to_exclude = []#[f.replace('_truncated.XDATCAR', '.XDATCAR') for f in truncated_files]\n",
    "\n",
    "# Exclude both truncated files and their base files\n",
    "path_all_ovito_files = [f for f in path_all_ovito_files if f not in truncated_files and f not in original_files_to_exclude]\n",
    "print(f\"Found {len(path_all_ovito_files)} ovito files to process.\")\n",
    "print(f'excluded {len(truncated_files)} truncated files and their base files.')\n",
    "print('\\n'.join(f'{i+1}. {f}' for i, f in enumerate(sorted(original_files_to_exclude))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c76b75",
   "metadata": {},
   "source": [
    "# truncate to only Li and X Atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd85a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99% \t Processing File 90/90\r"
     ]
    }
   ],
   "source": [
    "#todo: find a way to keep the labels of the frames\n",
    "def truncate_ovito_files(path_ovito_file, wanted_species=['Li','X']):\n",
    "    with open(path_ovito_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    step, time = [], []\n",
    "    for line in lines:\n",
    "        if 'step' in line:\n",
    "            words = line.split(' ')\n",
    "            step.append(int(words[1]))\n",
    "            time.append(float(words[3]))\n",
    "    \n",
    "    all_frames = read(path_ovito_file, index=':')\n",
    "    truncated_ovito_file = []\n",
    "    for n,atoms in enumerate(all_frames):  \n",
    "        indices = [i for i, atom in enumerate(atoms) if atom.symbol in wanted_species]\n",
    "        new_atoms = atoms[indices]\n",
    "        new_atoms.info = atoms.info\n",
    "        new_atoms.write(filename=path_ovito_file.replace('.XDATCAR', f'_truncated.XDATCAR'),\n",
    "                        format='vasp-xdatcar', append=True, label=f'step {step[n]} time {time[n]}')\n",
    "        truncated_ovito_file.append(new_atoms)      \n",
    "    #write(path_ovito_file.replace('.XDATCAR', '_truncated.XDATCAR'), truncated_ovito_file)\n",
    "    return truncated_ovito_file\n",
    "\n",
    "for i, path_ovito_file in enumerate(path_all_ovito_files):\n",
    "    progress_print(i, len(path_all_ovito_files))\n",
    "    truncate_ovito_files(path_ovito_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989ee97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1af46794",
   "metadata": {},
   "source": [
    "# find trunicated files ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33eabbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(simulation_folder, '**', '*_truncated.XDATCAR')\n",
    "path_truncated_files = sorted(glob.glob(pattern, recursive=True))\n",
    "print(f\"Found {len(path_truncated_files)} truncated files to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0f36e",
   "metadata": {},
   "source": [
    "# calculate Warren Cowley and safe it to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e26c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames: 142\t steps:142\ttime:1421/90\n",
      "Frames: 142\t steps:142\ttime:1422/90\n",
      "Frames: 142\t steps:142\ttime:1423/90\n",
      "Frames: 141\t steps:141\ttime:1414/90\n",
      "Frames: 143\t steps:143\ttime:1435/90\n",
      "Frames: 143\t steps:143\ttime:1436/90\n",
      "Frames: 143\t steps:143\ttime:1437/90\n",
      "Frames: 142\t steps:142\ttime:1428/90\n",
      "Frames: 141\t steps:141\ttime:1419/90\n",
      "Frames: 142\t steps:142\ttime:142 10/90\n",
      "Frames: 117\t steps:117\ttime:117 11/90\n",
      "Frames: 124\t steps:124\ttime:124 12/90\n",
      "Frames: 119\t steps:119\ttime:119 13/90\n",
      "Frames: 125\t steps:125\ttime:125 14/90\n",
      "Frames: 120\t steps:120\ttime:120 15/90\n",
      "Frames: 119\t steps:119\ttime:119 16/90\n",
      "Frames: 118\t steps:118\ttime:118 17/90\n",
      "Frames: 121\t steps:121\ttime:121 18/90\n",
      "Frames: 121\t steps:121\ttime:121 19/90\n",
      "Frames: 120\t steps:120\ttime:120 20/90\n",
      "Frames: 134\t steps:134\ttime:134 21/90\n",
      "Frames: 133\t steps:133\ttime:133 22/90\n",
      "Frames: 129\t steps:129\ttime:129 23/90\n",
      "Frames: 133\t steps:133\ttime:133 24/90\n",
      "Frames: 133\t steps:133\ttime:133 25/90\n",
      "Frames: 133\t steps:133\ttime:133 26/90\n",
      "Frames: 132\t steps:132\ttime:132 27/90\n",
      "Frames: 131\t steps:131\ttime:131 28/90\n",
      "Frames: 134\t steps:134\ttime:134 29/90\n",
      "Frames: 133\t steps:133\ttime:133 30/90\n",
      "Frames: 126\t steps:126\ttime:126 31/90\n",
      "Frames: 128\t steps:128\ttime:128 32/90\n",
      "Frames: 127\t steps:127\ttime:127 33/90\n",
      "Frames: 128\t steps:128\ttime:128 34/90\n",
      "Frames: 128\t steps:128\ttime:128 35/90\n",
      "Frames: 132\t steps:132\ttime:132 36/90\n",
      "Frames: 125\t steps:125\ttime:125 37/90\n",
      "Frames: 127\t steps:127\ttime:127 38/90\n",
      "Frames: 129\t steps:129\ttime:129 39/90\n",
      "Frames: 126\t steps:126\ttime:126 40/90\n",
      "Frames: 124\t steps:124\ttime:124 41/90\n",
      "Frames: 123\t steps:123\ttime:123 42/90\n",
      "Frames: 123\t steps:123\ttime:123 43/90\n",
      "Frames: 125\t steps:125\ttime:125 44/90\n",
      "Frames: 124\t steps:124\ttime:124 45/90\n",
      "Frames: 121\t steps:121\ttime:121 46/90\n",
      "Frames: 121\t steps:121\ttime:121 47/90\n",
      "Frames: 130\t steps:130\ttime:130 48/90\n",
      "Frames: 125\t steps:125\ttime:125 49/90\n",
      "Frames: 124\t steps:124\ttime:124 50/90\n",
      "Frames: 121\t steps:121\ttime:121 51/90\n",
      "Frames: 121\t steps:121\ttime:121 52/90\n",
      "Frames: 122\t steps:122\ttime:122 53/90\n",
      "Frames: 120\t steps:120\ttime:120 54/90\n",
      "Frames: 121\t steps:121\ttime:121 55/90\n",
      "Frames: 122\t steps:122\ttime:122 56/90\n",
      "Frames: 120\t steps:120\ttime:120 57/90\n",
      "Frames: 123\t steps:123\ttime:123 58/90\n",
      "Frames: 123\t steps:123\ttime:123 59/90\n",
      "Frames: 121\t steps:121\ttime:121 60/90\n",
      "Frames: 131\t steps:131\ttime:131 61/90\n",
      "Frames: 133\t steps:133\ttime:133 62/90\n",
      "Frames: 131\t steps:131\ttime:131 63/90\n",
      "Frames: 133\t steps:133\ttime:133 64/90\n",
      "Frames: 132\t steps:132\ttime:132 65/90\n",
      "Frames: 131\t steps:131\ttime:131 66/90\n",
      "Frames: 132\t steps:132\ttime:132 67/90\n",
      "Frames: 130\t steps:130\ttime:130 68/90\n",
      "Frames: 131\t steps:131\ttime:131 69/90\n",
      "Frames: 132\t steps:132\ttime:132 70/90\n",
      "Frames: 120\t steps:120\ttime:120 71/90\n",
      "Frames: 118\t steps:118\ttime:118 72/90\n",
      "Frames: 118\t steps:118\ttime:118 73/90\n",
      "Frames: 122\t steps:122\ttime:122 74/90\n",
      "Frames: 120\t steps:120\ttime:120 75/90\n",
      "Frames: 116\t steps:116\ttime:116 76/90\n",
      "Frames: 119\t steps:119\ttime:119 77/90\n",
      "Frames: 118\t steps:118\ttime:118 78/90\n",
      "Frames: 118\t steps:118\ttime:118 79/90\n",
      "Frames: 119\t steps:119\ttime:119 80/90\n",
      "Frames: 135\t steps:135\ttime:135 81/90\n",
      "Frames: 133\t steps:133\ttime:133 82/90\n",
      "Frames: 134\t steps:134\ttime:134 83/90\n",
      "Frames: 134\t steps:134\ttime:134 84/90\n",
      "Frames: 131\t steps:131\ttime:131 85/90\n",
      "Frames: 132\t steps:132\ttime:132 86/90\n",
      "Frames: 134\t steps:134\ttime:134 87/90\n",
      "Frames: 134\t steps:134\ttime:134 88/90\n",
      "Frames: 136\t steps:136\ttime:136 89/90\n",
      "Frames: 132\t steps:132\ttime:132 90/90\n"
     ]
    }
   ],
   "source": [
    "def create_warren_cowley_csv(structure_file):\n",
    "    \n",
    "    with open(structure_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    step, time = [], []\n",
    "    for line in lines:\n",
    "        if 'step' in line:\n",
    "            words = line.split(' ')\n",
    "            step.append(int(words[1]))\n",
    "            time.append(float(words[3]))\n",
    "        \n",
    "    ovito_file = import_file(structure_file)\n",
    "    \n",
    "    num_frames = ovito_file.source.num_frames\n",
    "    mod = wc.WarrenCowleyParameters(nneigh=[0, 6])\n",
    "    ovito_file.modifiers.append(mod)\n",
    "    \n",
    "    data = ovito_file.compute(0)\n",
    "    wc_names = list(data.attributes['Warren-Cowley parameters by particle name'][0].keys())\n",
    "    \n",
    "    wc_file = structure_file.replace('Ovito_truncated.XDATCAR', '_warren_cowley.csv')\n",
    "    with open(wc_file, 'w') as f:\n",
    "        f.write(f\"{'step':<7},\\t{'time':<15},\\t{wc_names[0]:<20},\\t{wc_names[1]:<20},\\t{wc_names[2]:<20},\\t{wc_names[3]:<20}\\n\")\n",
    "    print(f'Frames: {num_frames}\\t steps:{len(step)}\\ttime:{len(time)}')\n",
    "    # Iterate through frames\n",
    "    for frame in range(num_frames):\n",
    "        data = ovito_file.compute(frame)\n",
    "        wc_for_shells = data.attributes['Warren-Cowley parameters'][0]\n",
    "        with open(wc_file, 'a') as f:\n",
    "            f.write(\n",
    "                f\"{step[frame]:7},\\t{time[frame]:15},\\t{wc_for_shells[0][0]:20},\\t{wc_for_shells[0][1]:20},\\t\"\n",
    "                f\"{wc_for_shells[1][0]:20},\\t{wc_for_shells[1][1]:20}\\n\"\n",
    "            )\n",
    "    \n",
    "\n",
    "for i, path in enumerate(path_truncated_files):\n",
    "    progress_print(i, len(path_truncated_files))\n",
    "    create_warren_cowley_csv(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33e926",
   "metadata": {},
   "source": [
    "# Find Warren Cowley files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8047a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 warren cowley files to process.\n"
     ]
    }
   ],
   "source": [
    "pattern = os.path.join(simulation_folder, '**', '*_warren_cowley.csv')\n",
    "path_wc_files = sorted(glob.glob(pattern, recursive=True))\n",
    "paths_wc_files_clusterd = {} \n",
    "for path in path_wc_files:\n",
    "    dir_name = os.path.dirname(os.path.dirname(path)).split('/')[-1]\n",
    "    if dir_name not in paths_wc_files_clusterd:\n",
    "        paths_wc_files_clusterd[dir_name] = []\n",
    "    paths_wc_files_clusterd[dir_name].append(path)\n",
    "print(f\"Found {len(path_wc_files)} warren cowley files to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd7dbe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustered wc plots Progress: 100% \t Processing File 9/9\r"
     ]
    }
   ],
   "source": [
    "# plots for each warren cowley file\n",
    "for i, path in enumerate(path_wc_files):\n",
    "    progress_print(i, len(path_wc_files), 'single wc plots')\n",
    "    \n",
    "    # Read data\n",
    "    dataset = pd.read_csv(path, sep=r',\\s*', engine='python')\n",
    "    dataset.columns = dataset.columns.str.strip()\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Seaborn regression plot with scatter and confidence interval\n",
    "    # Using lowess=True for smooth non-linear curve (locally weighted regression)\n",
    "    sns.regplot(x='time', y='Li-X', data=dataset, \n",
    "                scatter_kws={'alpha':0.5, 's':20},\n",
    "                line_kws={'color':'red', 'linewidth':2},\n",
    "                lowess=True)\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Li-X')\n",
    "    plt.title('Warren-Cowley Parameter: Li-X vs Time')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path.replace('.csv', '_Li-X_warren_cowley.png'), dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "# plots for clustered warren cowley files\n",
    "for i, (cluster_name, paths) in enumerate(paths_wc_files_clusterd.items()):\n",
    "    progress_print(i, len(paths_wc_files_clusterd), f'clustered wc plots')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Combine all datasets from the cluster into one\n",
    "    all_datasets = []\n",
    "    for run_num, path in enumerate(paths):\n",
    "        dataset = pd.read_csv(path, sep=r',\\s*', engine='python')\n",
    "        dataset.columns = dataset.columns.str.strip()\n",
    "        dataset['run'] = f'Run {run_num+1}'\n",
    "        all_datasets.append(dataset)\n",
    "    \n",
    "    # Concatenate all data into single dataframe\n",
    "    combined_dataset = pd.concat(all_datasets, ignore_index=True)\n",
    "    \n",
    "    # Plot scatter with color by run\n",
    "    sns.scatterplot(x='time', y='Li-X', hue='run', data=combined_dataset, \n",
    "                    alpha=0.5, s=20)\n",
    "    \n",
    "    # Add single regression line (without hue)\n",
    "    sns.regplot(x='time', y='Li-X', data=combined_dataset, \n",
    "               scatter=False,\n",
    "               line_kws={'color':'red', 'linewidth':2},\n",
    "               lowess=True)\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Li-X')\n",
    "    plt.title(f'Warren-Cowley Parameter: Li-X vs Time for Cluster {cluster_name}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(simulation_folder, f'cluster_{cluster_name}_Li-X_warren_cowley.png'), dpi=150)\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
