{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a05dcb57-36ef-46b7-9bdb-bfe20a2afbfd",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7b666-1d2f-49c1-8d52-03ffb5d64913",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74224aca-eb1f-48cc-916a-c9a0daebe569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:21.565384Z",
     "start_time": "2025-03-06T16:57:19.079530Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfshome/winkelmann/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+01, tolerance: 2.402e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/nfshome/winkelmann/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+01, tolerance: 2.410e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Modules are available in conda environment with name: icet\n",
    "# conda activate icet\n",
    "\n",
    "import ase\n",
    "from ase.io import read as ASEread\n",
    "from ase.io.vasp import write_vasp\n",
    "from ase.db import connect\n",
    "from ase.cell import Cell\n",
    "from ase.neighborlist import NewPrimitiveNeighborList\n",
    "from ase.build import make_supercell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import colormaps\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import icet\n",
    "from icet import ClusterSpace, StructureContainer, ClusterExpansion\n",
    "from trainstation import CrossValidationEstimator\n",
    "from icet.tools import enumerate_structures\n",
    "from icet.tools.structure_generation import generate_sqs_by_enumeration\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_context('notebook')\n",
    "except ImportError:\n",
    "    print('sad')\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c6698-284f-4520-8ec0-3e37dd2530be",
   "metadata": {},
   "source": [
    "## Misc Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eccef56b-63c3-4529-b4c1-26fc2b37ad25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:21.571703Z",
     "start_time": "2025-03-06T16:57:21.568764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stop message\n",
    "def jupyter_stop(ErrorMessage=\"User-defined stop via jupyter_stop() function\"):\n",
    "    \"\"\"\n",
    "    User defined stop function, similar to exit(). Mostly for testing purpose or to \n",
    "    avoid overwriting of already generated data.\n",
    "    \"\"\"\n",
    "    raise SystemExit(ErrorMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad42dd-452a-4452-b4e9-bc191ce9eba9",
   "metadata": {},
   "source": [
    "## CE Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36111f-9653-4981-8db5-00753bce4ea3",
   "metadata": {},
   "source": [
    "## Reorder Atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe734d9-04a2-422d-89fd-fd08eab2bee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:21.645558Z",
     "start_time": "2025-03-06T16:57:21.642555Z"
    }
   },
   "outputs": [],
   "source": [
    "# S only in this list to 'trick' the structure enumeration\n",
    "# S as extra Nickel\n",
    "atomic_label2number = {\"Li\" :  3,\n",
    "                       \"O\"  :  8,\n",
    "                       \"S\"  : 16,\n",
    "                       \"Ni\" : 28}\n",
    "\n",
    "atomic_number2label = { 3 : \"Li\",\n",
    "                        8 :  \"O\",\n",
    "                       16 :  \"S\",\n",
    "                       28 :  \"Ni\"}\n",
    "\n",
    "\n",
    "def order_atoms(atoms,order=[\"Li\",\"Ni\",\"O\"]):\n",
    "    \n",
    "    # get old positions and atomic numbers\n",
    "    old_positions       = atoms.get_positions()\n",
    "    old_atomic_number   = atoms.get_atomic_numbers()\n",
    "    \n",
    "    # create empty dict for all types\n",
    "    atomic_pos_dict = {}\n",
    "    for sym in order:\n",
    "        atomic_pos_dict[sym] = []\n",
    "    \n",
    "    # append positions to dict \n",
    "    for num, pos in zip(old_atomic_number, old_positions):\n",
    "        atomic_pos_dict[atomic_number2label[num]].append(pos)\n",
    "    \n",
    "    # put together the new ordered positions and atomic numbers\n",
    "    new_positions = []\n",
    "    new_atomic_numbers = []\n",
    "    for sym in order:\n",
    "        new_positions.extend(atomic_pos_dict[sym])\n",
    "        new_atomic_numbers.extend( [ atomic_label2number[sym] ] * len(atomic_pos_dict[sym]) )\n",
    "    \n",
    "    # copy original atoms object and modify it\n",
    "    copy_atoms = atoms.copy()\n",
    "    copy_atoms.set_positions(new_positions)\n",
    "    copy_atoms.set_atomic_numbers(new_atomic_numbers)\n",
    "    \n",
    "    return copy_atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84770b26-c060-49d0-b3eb-f831bcd57ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:21.703088Z",
     "start_time": "2025-03-06T16:57:21.692474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic setups\n",
    "\n",
    "def get_fit_data(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions):\n",
    "    \"\"\"\n",
    "    Construct cluster space and structure container for the given cutoffs\n",
    "    and return the fit matrix along with the target energies\n",
    "    \"\"\"\n",
    "    # stepsize to print update of training:\n",
    "    stepsize = int(0.1*len(outcar_list))\n",
    "    \n",
    "    # Collect the mapped structures\n",
    "    mapped_structures = []\n",
    "    \n",
    "    # Set up Clusterspace\n",
    "    cs = ClusterSpace(structure=prim,\n",
    "                      cutoffs=cutoffs,\n",
    "                      chemical_symbols=chemical_symbols,\n",
    "                      position_tolerance=position_tolerance,\n",
    "                      symprec=symprec)\n",
    "    \n",
    "    #print(cs)\n",
    "    \n",
    "    # Set up StructureContainer with the previsouly generated ClusterSpace\n",
    "    sc = StructureContainer(cluster_space=cs)\n",
    "    \n",
    "    # Fill the StructureContainer\n",
    "    for i, (outcar, E, at_ref) in enumerate(zip(outcar_list, energy_list, atoms_ref_list)):\n",
    "        \n",
    "        # print update of training\n",
    "        # if i % stepsize == 0:\n",
    "        #     print(f\"Computing structure {i} of {len(outcar_list)} ({i/len(outcar_list):.1%})   {datetime.datetime.now()}\")\n",
    "        \n",
    "        \n",
    "        # Read the OUTCAR [by default last step is used] and get energy\n",
    "        #at     = ASEread(outcar)\n",
    "        #total_energy = at.get_potential_energy() # total_energy = atoms.get_potential_energy(force_consistent=True)\n",
    "        \n",
    "        # Map the enumerated structure to the primitive cell, add it to cluster space with the energy of the properly relaxed system\n",
    "        try:\n",
    "            mapped_atoms, info = icet.tools.map_structure_to_reference(structure=at_ref, \n",
    "                                                             reference=prim, \n",
    "                                                             inert_species=[\"O\"], \n",
    "                                                             tol_positions=tol_positions, \n",
    "                                                             suppress_warnings=False, \n",
    "                                                             assume_no_cell_relaxation=False)\n",
    "            mapped_structures.append(mapped_atoms)\n",
    "\n",
    "            sc.add_structure(structure=mapped_atoms,\n",
    "                     properties={'Total Energy': E},\n",
    "                     user_tag = outcar,\n",
    "                     sanity_check=True,\n",
    "                     )\n",
    "        \n",
    "        except ValueError as err:\n",
    "            print(f\"Mapping Error with {outcar}\")\n",
    "            print(f\"Note: Possibly a different structure was used for the mapping!\")\n",
    "            print(\"Original Error Message:\")\n",
    "            print(err , \"\\n\")\n",
    "            \n",
    "\n",
    "            \n",
    "    print(f\"len(cs) = {len(cs)}\")\n",
    "    \n",
    "    return sc.get_fit_data(key='Total Energy'), mapped_structures\n",
    "\n",
    "\n",
    "def get_A_y(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions):\n",
    "    return get_fit_data(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions)\n",
    "\n",
    "\n",
    "\n",
    "def get_row(cve, alpha=None):\n",
    "    row = dict()\n",
    "    row['rmse_validation'] = cve.rmse_validation\n",
    "    row['rmse_train'] = cve.rmse_train\n",
    "    row['BIC'] = cve.model.BIC\n",
    "    row['n_parameters'] = cve.n_parameters\n",
    "    row['n_nonzero_parameters'] = cve.n_nonzero_parameters\n",
    "    \n",
    "    if alpha != None:\n",
    "        row['alpha'] = alpha\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "def train_ce(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions, fit_method):\n",
    "    \"\"\"\n",
    "    Train a cluster expansion with the given cutoffs and return fit metrics of the obtained model.\n",
    "    prim: ase atoms object, its the primitive structure that the CE lives on\n",
    "    chemical_symbols: List of the possible atoms types on the different sites of prim\n",
    "    cutoffs: cutoffs for the 2-body, 3-body, ... terms\n",
    "    atoms_list: list of all the atoms objects to use for training/testing\n",
    "    outcar_list : list with paths (strings) of the corresponding atoms objects\n",
    "    fit_method examples with additional options (to be implemented at a later point): \n",
    "        fit_method='rfe'\n",
    "        fit_method='ardr', threshold_lambda=4e5\n",
    "        fit_method='ardr', line_scan=True\n",
    "        fit_method='lasso'\n",
    "        fit_method='least-squares'\n",
    "    \"\"\"\n",
    "    (A, y), mapped_structures = get_fit_data(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions)\n",
    "    n_splits=10\n",
    "    if fit_method == 'ardr-lambda':\n",
    "        cve = CrossValidationEstimator((A, y), fit_method='ardr', threshold_lambda=1000, validation_method='shuffle-split', n_splits=n_splits)\n",
    "    elif fit_method == 'ardr-lineScan':\n",
    "        cve = CrossValidationEstimator((A, y), fit_method='ardr', line_scan=True, validation_method='shuffle-split', n_splits=n_splits)\n",
    "    else:\n",
    "        cve = CrossValidationEstimator((A, y), fit_method=fit_method, validation_method='shuffle-split', n_splits=n_splits)\n",
    "    # print(f'starting validation with {fit_method} algorithm  {datetime.datetime.now()}')\n",
    "    cve.validate()\n",
    "    cve.train()\n",
    "\n",
    "    row = get_row(cve)\n",
    "    \n",
    "    return cve\n",
    "\n",
    "def prevent_override(path):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(path):\n",
    "        return path\n",
    "    # Get the file name and extension\n",
    "    base, ext = os.path.splitext(path)\n",
    "    # Initialize a counter\n",
    "    counter = 1\n",
    "    # Loop to find a non-existing file name\n",
    "    while os.path.exists(f\"{base}_{counter}{ext}\"):\n",
    "        counter += 1\n",
    "    # Return the new file name\n",
    "    return f\"{base}_{counter}{ext}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b8a37-f885-48e3-8f5f-1db44c0663da",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967ec400-e11b-49cc-b5f3-0467234e6013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:21.818455Z",
     "start_time": "2025-03-06T16:57:21.740031Z"
    }
   },
   "outputs": [],
   "source": [
    "### Get the reference energies of LiNiO2 and NiO2 normed per unit cell\n",
    "LiNiO2 = ASEread(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/02_enumerate_P21c_0-4fu/0001_finished_approved/run_final_approved/OUTCAR\")\n",
    "E_ref_LiNiO2_per_O2 = LiNiO2.get_potential_energy() / LiNiO2.get_chemical_symbols().count(\"O\") * 2 #or per Ni in case of no extra Ni\n",
    "\n",
    "NiO2   = ASEread(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/02_enumerate_P21c_0-4fu/0003_finished_approved/run_final_approved/OUTCAR\")\n",
    "E_ref_NiO2_per_O2   = NiO2.get_potential_energy() / NiO2.get_chemical_symbols().count(\"O\") * 2 #or per Ni in case of no extra Ni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a39b7-9176-4e06-9a47-475963e8839b",
   "metadata": {},
   "source": [
    "## Own enumerated structures based on P21/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eab6429-e300-41d3-8141-6846d035a46c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:44.773316Z",
     "start_time": "2025-03-06T16:57:21.820793Z"
    }
   },
   "outputs": [],
   "source": [
    "#Li verteilung ohne trans\n",
    "atoms_for_training_from_own_enumerated_structures = []\n",
    "H_o_M_for_training_from_own_enumerated_structures = []\n",
    "\n",
    "# Get all the outcars of interest\n",
    "outcars_for_training_from_own_enumerated_structures= sorted(glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/02_enumerate_P21c_0-4fu/0*_finished_approved/run_final_approved/OUTCAR\"))\n",
    "\n",
    "# Iterate over them\n",
    "for outcar in outcars_for_training_from_own_enumerated_structures:\n",
    "\n",
    "    # get atoms object\n",
    "    atoms = ASEread(outcar, index=\":\")\n",
    "\n",
    "    # Compute total heat of mixing\n",
    "    Li_count = atoms[-1].get_chemical_symbols().count(\"Li\")\n",
    "    O_count  = atoms[-1].get_chemical_symbols().count(\"O\")\n",
    "    H_o_M    = atoms[-1].get_potential_energy() - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2 - Li_count) * E_ref_NiO2_per_O2\n",
    "\n",
    "    # Append data...\n",
    "    # ... but to make mapping easier take the originally generated structures instead of the relaxed ones\n",
    "    ref = \"/\".join(outcar.split(\"/\")[:-2]) + \"/POSCAR_enumerated\"\n",
    "    atoms_for_training_from_own_enumerated_structures.append(ASEread(ref))        # total number of lattice sites:\n",
    "    # O_count   for Oxygen\n",
    "    # O_count/2 for Li-Sites\n",
    "    # O_count/2 for Ni-Sites\n",
    "    # = 2*O_count --> Lattice Sites\n",
    "    H_o_M_for_training_from_own_enumerated_structures.append( H_o_M / (2*O_count) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efd88e-7c3f-416f-9e2a-4f7c6d72e639",
   "metadata": {},
   "source": [
    "## Markus low energy CE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d3f0df-9b78-4e97-b2dc-c47deff4363c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:44.781130Z",
     "start_time": "2025-03-06T16:57:44.779569Z"
    }
   },
   "outputs": [],
   "source": [
    "# The following code takes Markus' relaxed structures and rotates them around the ccartesian z axis to fit the primitive structure we are using\n",
    "# Does not need to be run again\n",
    "# REMOVED error so it can run through until optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343c110c-8635-41db-baa6-d10436ebafa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:57:50.323266Z",
     "start_time": "2025-03-06T16:57:44.821291Z"
    }
   },
   "outputs": [],
   "source": [
    "#Li verteilung ohne trans\n",
    "# Compare Markus last step energy and volume with the ones re-relaxed from me\n",
    "# To this end, use the README files where \n",
    "\n",
    "atoms_for_training_from_Markus_low_energy_structures   = []\n",
    "H_o_M_for_training_from_Markus_low_energy_structures   = []\n",
    "outcars_for_training_from_Markus_low_energy_structures = []\n",
    "\n",
    "READMEs = glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/03_Markus_approved_low_energy_data/*/README_original_path_from_Markus\")\n",
    "\n",
    "for README in READMEs:\n",
    "    \n",
    "    if os.path.isdir(README.replace(\"README_original_path_from_Markus\",\"run_final\")):\n",
    "    \n",
    "        # get the transformed CONTCAR to enable correct mapped to our prim structure later\n",
    "        # Only for the 2 structures that made problems, take the original (rotated) POSCAR to enable mapping later\n",
    "        if \"re-relax_Markus038_finished\" in README or \"re-relax_Markus115_finished\" in README:\n",
    "            with open(README, \"r\") as f:\n",
    "                line = f.readlines()[0]\n",
    "            transformed_contcar = \"/\".join(line.split(\"/\")[0:-1]) + \"/run01/POSCAR_rotated.vasp\" \n",
    "        else:\n",
    "            transformed_contcar = README.replace(\"README_original_path_from_Markus\",\"run_final/CONTCAR_rotated.vasp\")\n",
    "        atoms_transformed_contcar = ASEread(transformed_contcar)\n",
    "        atoms_for_training_from_Markus_low_energy_structures.append(atoms_transformed_contcar)\n",
    "        \n",
    "        # get the outcar from the relaxation to get the energy\n",
    "        outcar = README.replace(\"README_original_path_from_Markus\",\"run_final/OUTCAR\")\n",
    "        outcars_for_training_from_Markus_low_energy_structures.append(outcar)\n",
    "        atoms = ASEread(outcar, index=\":\")\n",
    "\n",
    "        # Compute heat of mixing and per atom\n",
    "        Li_count = atoms[-1].get_chemical_symbols().count(\"Li\")\n",
    "        O_count  = atoms[-1].get_chemical_symbols().count(\"O\")\n",
    "        H_o_M    = atoms[-1].get_potential_energy() - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2 - Li_count) * E_ref_NiO2_per_O2\n",
    "        # total number of lattice sites:\n",
    "        # O_count   for Oxygen\n",
    "        # O_count/2 for Li-Sites\n",
    "        # O_count/2 for Ni-Sites\n",
    "        # = 2*O_count --> Lattice Sites\n",
    "        H_o_M_for_training_from_Markus_low_energy_structures.append( H_o_M / (2*O_count) )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd533b-245a-46de-b855-0f88799c0291",
   "metadata": {},
   "source": [
    "## NEB initial and final images (without Ni_Li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6459350f-04de-4dd3-bd94-2601dd605071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:58:13.670706Z",
     "start_time": "2025-03-06T16:57:50.330091Z"
    }
   },
   "outputs": [],
   "source": [
    "#Li verteilung ohne trans\n",
    "atoms_for_training_NEB_initial_and_final_images = []\n",
    "H_o_M_for_training_NEB_initial_and_final_images = []\n",
    "\n",
    "# Find the ordered ones from 0250, 0500 and 0750 first\n",
    "outcars_for_training_NEB_initial_and_final_images  = glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0250/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0500/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0750/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "\n",
    "# and the ones from the random structures\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/01_initial_structure/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/02_odh/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/03_tsh/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/04_double_tsh/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "\n",
    "# Iterate over OUTCARs\n",
    "for OUTCAR in outcars_for_training_NEB_initial_and_final_images:\n",
    "    \n",
    "    # get the atoms object\n",
    "    atoms = ASEread(OUTCAR, index=\":\") \n",
    "    \n",
    "    # Compute heat of mixing and per atom\n",
    "    Li_count = atoms[-1].get_chemical_symbols().count(\"Li\")\n",
    "    O_count  = atoms[-1].get_chemical_symbols().count(\"O\")\n",
    "    H_o_M    = atoms[-1].get_potential_energy() - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2 - Li_count) * E_ref_NiO2_per_O2\n",
    "        \n",
    "    # append them to the lists\n",
    "    atoms_for_training_NEB_initial_and_final_images.append(atoms[-1])\n",
    "    # total number of lattice sites:\n",
    "    # O_count   for Oxygen\n",
    "    # O_count/2 for Li-Sites\n",
    "    # O_count/2 for Ni-Sites\n",
    "    # = 2*O_count --> Lattice Sites\n",
    "    H_o_M_for_training_NEB_initial_and_final_images.append( H_o_M / (2*O_count) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d33a1-ac96-44c4-8d1c-d0d1173c3321",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NEB transition states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624b7ec2-184f-4492-93ba-b0397766787f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:59:32.258706Z",
     "start_time": "2025-03-06T16:58:13.677881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \t Could not read /nfshome/winkelmann/ARL/NEBs_Marcel/0375_random02_seed_85/02_odh/NEB_initial-image01/run_final_decided_to_be_converged_patchworked/01/OUTCAR\n",
      "2. \t Could not read /nfshome/winkelmann/ARL/NEBs_Marcel/0375_random02_seed_85/02_odh/NEB_initial-image01/run_final_decided_to_be_converged_patchworked/04/OUTCAR\n",
      "1. \t Could not read /nfshome/winkelmann/ARL/NEBs_Marcel/0625_random01_seed_178/04_double_tsh/NEB_initial-image02/run_final_patchworked_decided_to_be_converged/05/OUTCAR\n",
      "1. \t Could not read /nfshome/winkelmann/ARL/NEBs_Marcel/0625_random02_seed_258/04_double_tsh/NEB_initial-image04/run_final_patchworked/05/OUTCAR\n"
     ]
    }
   ],
   "source": [
    "#Li-trans\n",
    "\n",
    "atoms_for_training_NEB_transition_states = []\n",
    "H_o_M_for_training_NEB_transition_states = []\n",
    "paths_for_training_NEB_transition_states = []\n",
    "\n",
    "# the ones generated manually (0250, 0500, 0750)\n",
    "paths_for_training_NEB_transition_states  = glob.glob(\"/nfshome/winkelmann/ARL/NEBs_Marcel/*/NEB_*/run_final*\")\n",
    "\n",
    "# the random ones\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/winkelmann/ARL/NEBs_Marcel/*random*/02_odh/NEB*/run_final*\")\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/winkelmann/ARL/NEBs_Marcel/*random*/03_tsh/NEB*/run_final*\")\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/winkelmann/ARL/NEBs_Marcel/*random*/04_double_tsh/NEB*/run_final*\")\n",
    "\n",
    "# Iterate over all run_final folders\n",
    "for path in paths_for_training_NEB_transition_states:\n",
    "    #get the folder path\n",
    "    source_folder = '/'.join(path.split('/')[0:-1])\n",
    "    # Check the energy along the path. Use initial and final energies from the corresponding relaxed structures + the last steps of the \n",
    "    # optimized intermediate images\n",
    "    energies = []\n",
    "    energies.append(ASEread(source_folder + \"/OUTCAR_initial_image\").get_potential_energy())\n",
    "    could_not_read_counter = 0\n",
    "    for i in [\"01\", \"02\", \"03\", \"04\", \"05\"]:\n",
    "        try:\n",
    "            energies.append(ASEread(f\"{path}/{i}/OUTCAR\").get_potential_energy())\n",
    "        except:\n",
    "            could_not_read_counter += 1\n",
    "            print(f\"{could_not_read_counter}. \\t Could not read {path}/{i}/OUTCAR\")\n",
    "    if could_not_read_counter == 5:\n",
    "        print(f\"Ignore {path}\\n  ---> could not read any OUTCARs!\")\n",
    "        continue\n",
    "    energies.append(ASEread(source_folder + \"/OUTCAR_final_image\").get_potential_energy())\n",
    "    \n",
    "    # For \"Proper\" paths, there should be maximum in energy !between! initial and final paths... ignore those where this is not the case\n",
    "    index_highest_energy = energies.index(max(energies))\n",
    "    \n",
    "    if index_highest_energy == 0 or index_highest_energy == 6:\n",
    "        print(f\"Ignore {path}\\n  ---> image {index_highest_energy} has highest energy!\")\n",
    "    \n",
    "    else:    \n",
    "        # get the interpolated middle points of the initially created, straight odh-type path to be used as ideal position for the CE training\n",
    "        ideal_TS_structure_file = glob.glob(source_folder + \"/anchor_trans_image.vasp\")\n",
    "        ideal_TS_atoms = ASEread(ideal_TS_structure_file[0])\n",
    "     \n",
    "        atoms_for_training_NEB_transition_states.append(ideal_TS_atoms)\n",
    "        \n",
    "        # Compute heat of mixing per atom and append to list\n",
    "        Li_count = ideal_TS_atoms.get_chemical_symbols().count(\"Li\") + 1 # +1 for the jumping Li\n",
    "        O_count  = ideal_TS_atoms.get_chemical_symbols().count(\"O\")\n",
    "        H_o_M    = max(energies) - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "        # total number of lattice sites:\n",
    "        # O_count   for Oxygen\n",
    "        # O_count/2 for Li-Sites\n",
    "        # O_count/2 for Ni-Sites\n",
    "        # = 2*O_count --> Lattice Sites\n",
    "        H_o_M_for_training_NEB_transition_states.append( H_o_M / (2*O_count) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c549a-b563-43e4-bded-dd79ecf3b05f",
   "metadata": {},
   "source": [
    "## Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d64a18-03b0-4813-a70e-458e90493daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:59:32.277202Z",
     "start_time": "2025-03-06T16:59:32.274642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nonTS-Structures:\t 882\n",
      "# TS-Structures:\t 135\n"
     ]
    }
   ],
   "source": [
    "# combine the structures \n",
    "train_structures = ( atoms_for_training_from_own_enumerated_structures \n",
    "                    + atoms_for_training_from_Markus_low_energy_structures\n",
    "                    + atoms_for_training_NEB_initial_and_final_images \n",
    "                    + atoms_for_training_NEB_transition_states \n",
    "             )\n",
    "\n",
    "# ... and energies\n",
    "train_H_o_M      = ( H_o_M_for_training_from_own_enumerated_structures \n",
    "                     + H_o_M_for_training_from_Markus_low_energy_structures\n",
    "                     + H_o_M_for_training_NEB_initial_and_final_images \n",
    "                     + H_o_M_for_training_NEB_transition_states \n",
    "             )\n",
    "\n",
    "# to be able to retrieve problematic files, keep the paths\n",
    "file_location = ( outcars_for_training_from_own_enumerated_structures \n",
    "                + outcars_for_training_from_Markus_low_energy_structures \n",
    "                + outcars_for_training_NEB_initial_and_final_images \n",
    "                + paths_for_training_NEB_transition_states\n",
    "                )\n",
    "# calc and print how many non Ts and TS structures are used for training\n",
    "no_nonTS_structures = len( outcars_for_training_from_own_enumerated_structures \n",
    "                           + outcars_for_training_from_Markus_low_energy_structures \n",
    "                           + outcars_for_training_NEB_initial_and_final_images)\n",
    "no_TS_structures = len(paths_for_training_NEB_transition_states)\n",
    "\n",
    "print('# nonTS-Structures:\\t', no_nonTS_structures)\n",
    "print('# TS-Structures:\\t', no_TS_structures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f94a7-ec2f-42e9-a7a1-d0f27e68fe12",
   "metadata": {},
   "source": [
    "# Fitting of just the Li sublattice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490984ab36eb0133",
   "metadata": {},
   "source": [
    "without TS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8f14cdd30c531",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<font color='red'> deleted traing of ardr_lambda </font>\n",
    "just left the setting of the Clusterspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d50ce54a3dc25f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<font color='red'> deleted code cell for calculating with the model with respect to the trained structure </font>\n",
    "kept initalization of data[] (without predicted_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1897762577fad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "<font color='red'> deleted code cell for plotting the ardr_lambda fitting vs reference data with respect to the diffrent data sets </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f72e76-d59b-4d35-8b15-0b3f90824535",
   "metadata": {},
   "source": [
    "# First fitting for testing purposes of python implementation (no Ni_Li, but with transition states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eacb7d08-14fb-4955-ab0c-7a7c4f741b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:59:32.458263Z",
     "start_time": "2025-03-06T16:59:32.453395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='LiNiO2', pbc=True, cell=[[2.8428983688, 0.0, 0.0], [-1.4214491844, 2.4620222078, 0.0], [1.42145, 0.82067, 4.71521]])\n",
      "['Li', 'Ni', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Read R-3m model of LiNiO2 in R-3m symmetry with transition states\n",
    "prim_TS = ASEread(\"/nfshome/sadowski/work/LiNiO2_Sabrina/37_CE_for_Li_diffusion/00_LNO_R-3m.vasp\")\n",
    "\n",
    "print(prim_TS)\n",
    "print(prim_TS.get_chemical_symbols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cdaf2a5-1537-452a-a989-7d8c394f258c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:59:32.558823Z",
     "start_time": "2025-03-06T16:59:32.556651Z"
    }
   },
   "outputs": [],
   "source": [
    "chemical_symbols_TS= [['Li', 'X', 'Ti'],   # Li sublattice will contain: Li and Vacancies (=X), later also Ni\n",
    "                    ['Ni'],       # Ni sublattice will not be changed\n",
    "                    ['O'],        # O  sublattice will not be changed\n",
    "                    ['O']]        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371a87e7cb3d0c3",
   "metadata": {},
   "source": [
    "Idee pickle here (als binÃ¤rdaten speichern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054b42820f76f64",
   "metadata": {},
   "source": [
    "# Optimizing CE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae8b22512b9e4c",
   "metadata": {},
   "source": [
    "## finding cutoffs\n",
    "list possile cutoffs and define standard variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f13618562eec535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T16:59:32.607930Z",
     "start_time": "2025-03-06T16:59:32.603212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ardr-lambda:\t[11.38, 6.42, 6.42]\n",
      " ardr-lineScan:\t[12.83, 6.42, 5.69]\n",
      "           rfe:\t[11.84, 6.42, 5.75]\n",
      "         lasso:\t[12.75, 6.42, 5.69]\n",
      " least-squares:\t[11.84, 6.42, 5.69]\n",
      "bayesian-ridge:\t[11.84, 6.42, 5.69]\n",
      "    elasticnet:\t[12.4, 6.42, 5.75]\n",
      "           omp:\t[11.5, 6.42, 5.69]\n",
      "         ridge:\t[11.84, 6.42, 5.69]\n",
      " split-bregman:\t[11.84, 6.42, 5.69]\n"
     ]
    }
   ],
   "source": [
    "# read results cutoffs_noTS\n",
    "best_cutoffs_noTS = {}\n",
    "    \n",
    "file = open('/nfshome/winkelmann/ARL/save/best_cutoffs_noTS.csv','r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "    \n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    best_cutoffs_noTS[values[0]] = [float(values[1]), float(values[2]), float(values[3])]\n",
    "    print('%14s:\\t%s' % (values[0], best_cutoffs_noTS[values[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e5cce5c4ca411f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:02:43.517691Z",
     "start_time": "2025-03-06T17:02:43.515034Z"
    }
   },
   "outputs": [],
   "source": [
    "import time as pytime\n",
    "\n",
    "cutoff_vals = [2.84, 2.85, ] # till 8.09 - biggest cutoff so the transition stated does not see itself\n",
    "# \n",
    "position_tolerance = 0.01\n",
    "symprec = 0.01\n",
    "tol_positions=0.05\n",
    "\n",
    "fit_methods_all = ['ardr-lambda', 'rfe', 'lasso', 'least-squares', 'bayesian-ridge', 'omp', 'ridge', 'split-bregman', 'elasticnet', 'ardr-lineScan']\n",
    "fit_methods = ['ardr-lambda', 'rfe', 'lasso', 'least-squares', 'bayesian-ridge', 'omp', 'ridge', 'split-bregman', 'elasticnet', 'ardr-lineScan']\n",
    "# \n",
    "records = {}\n",
    "#todo: look at TS-mapped in ovito\n",
    "#todo: try weighting TS --> not working       \n",
    "#        #weighting TS-Structures higher\n",
    "#        weights = np.ones(len(y))\n",
    "#        for structure, weight in zip(train_structures, weights):\n",
    "#            if structure in atoms_for_training_NEB_transition_states:\n",
    "#                weight = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2aa37acd115ff27e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:02:05.148093Z",
     "start_time": "2025-03-06T17:02:05.145879Z"
    }
   },
   "outputs": [],
   "source": [
    "#initalizoing savefiles to prevent naming it on several ocasions\n",
    "save_file_pair_cutoffs = '/nfshome/winkelmann/ARL/tmp/cutoffs_2_anchor_fit'\n",
    "save_file_triplet_cutoffs = '/nfshome/winkelmann/ARL/tmp/cutoffs_3_anchor_fit'\n",
    "save_file_quartet_cutoffs = '/nfshome/winkelmann/ARL/tmp/cutoffs_4_anchor_fit'\n",
    "save_file_best_cutoffs = '/nfshome/winkelmann/ARL/tmp/best_cutoffs_anchor_fit'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec5ccff06d4e49",
   "metadata": {},
   "source": [
    "### pair cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71581fcf2bea6b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T14:24:37.308247760Z",
     "start_time": "2025-02-27T14:33:35.471664Z"
    }
   },
   "outputs": [],
   "source": [
    "save_file_pair_cutoffs = prevent_override(save_file_pair_cutoffs)\n",
    "file = open(save_file_pair_cutoffs, 'w')\n",
    "file_format = '%14s,\\t%20s,\\t%13s,\\t%15s,\\t%15s,\\t%15s,\\t%7s,\\t%7s,\\t%7s' + os.linesep\n",
    "file.write(file_format % ('fit_method', 'cutoffs' , 'cutoff2', 'validation', 'train', 'BIC', 'number', 'nonzero','time'))\n",
    "file.close()\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method] = []\n",
    "    c2_vals = cutoff_vals\n",
    "    for c2 in c2_vals:\n",
    "        start_time = pytime.time()\n",
    "        cutoffs = best_cutoffs_noTS[fit_method]\n",
    "        cutoffs[0] = c2\n",
    "        cve = train_ce(prim=prim_TS,\n",
    "                       chemical_symbols=chemical_symbols_TS,\n",
    "                       cutoffs=cutoffs,\n",
    "                       energy_list=train_H_o_M,\n",
    "                       atoms_ref_list=train_structures,\n",
    "                       outcar_list=file_location,\n",
    "                       position_tolerance=position_tolerance,\n",
    "                       symprec=symprec,\n",
    "                       tol_positions=tol_positions,\n",
    "                       fit_method=fit_method)\n",
    "        records[fit_method].append({'c2': c2, **cve})\n",
    "        file = open(save_file_pair_cutoffs, 'a')\n",
    "        file.write(file_format % (fit_method, cutoffs, c2, cve.rmse_validation, cve.rmse_train, cve.model.BIC, cve.n_parameters, cve.n_nonzero_parameters, pytime.time()-start_time))\n",
    "        file.close()                       \n",
    "\n",
    "#Total number of Li-Li Bonds as function of cutoff (intra layer/inter layer):\n",
    "#                       same Layer          next layer x2   second next layer x2\n",
    "# 2.84    0  ( 0/ 0)    \n",
    "# 2.85    6  ( 6/ 0)    first  (6)\n",
    "# 4.93   12  (12/ 0)    second (6)\n",
    "# 5.00   18  (12/ 6)                        first  (3) \n",
    "# 5.69   24  (18/ 6)    third  (6)\n",
    "# 5.75   30  (18/12)                        second (3) \n",
    "# 6.42   42  (18/24)                        third  (6) \n",
    "# 7.53   54  (30/24)    fourth (12) \n",
    "# 7.57   66  (30/36)                        fourth (6) \n",
    "# 8.09   72  (30/42)                        fifth  (3) \n",
    "# 8.53   78  (36/42)    fifth  (6)\n",
    "# 8.57   90  (36/54)                        sixth  (6) \n",
    "# 9.47   96  (36/60)                        seventh(3)\n",
    "# 9.58  102  (36/60/6)                                      first  (3)\n",
    "# 9.85  108  (42/60/6)  sixth  (6)          \n",
    "# 9.89  120  (42/72/6)                      eigth  (6)\n",
    "#10.00  126  (42/72/12)                                     second (3)\n",
    "#10.26  138  (54/72/12) seventh(12)\n",
    "#10.29  150  (54/84/12)                     ninth  (6)\n",
    "#10.39  162  (54/84/24)                                     third  (6)\n",
    "#11.10  174  (54/96/24)                     tenth(6)\n",
    "#11.14  186  (54/96/36)                                     fourth(6)\n",
    "#11.38  192  (60/96/36) eighth(6)\n",
    "#11.50  198  (60/96/42)                                     fifth(3)\n",
    "#11.76  210  (60/108/42)                    ninth(6)\n",
    "#11.84  222  (60/108/54)                                    sixth(6)\n",
    "#12.40  234  (72/108/54) ninth(12)\n",
    "#12.42  252  (72/126/54)                    tenth(9)\n",
    "#12.51  258  (72/126/60)                                    seventh(3)\n",
    "#12.75  270  (72/138/60)                    eleventh(6)\n",
    "#12.83  282  (72/138/72)                                    eighth(6)\n",
    "#13.03  294  (84/138/72) tenth(12)\n",
    "#13.14  306  (84/138/84)                                    ninth(6)\n",
    "#13.66  318  (84/150/84)                    twelfth(6)\n",
    "#13.74  330  (84/150/96)                                    tenth(6)\n",
    "#13.96  336  (84/156/96)                    thiteenth(3)\n",
    "#14.15  338  (84/156/96/2)                                                  first(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e8779ed87b90b",
   "metadata": {},
   "source": [
    "### triplett cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a92390e33227f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T17:02:45.434442Z",
     "start_time": "2025-03-06T17:02:45.421548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pair cutoff: 8.09\n"
     ]
    }
   ],
   "source": [
    "# read results cutoff2\n",
    "\n",
    "best_cutoffs2 = {}\n",
    "df2 = {}\n",
    "\n",
    "for fit_method in fit_methods_all:\n",
    "    df2[fit_method] = {'c2': [], 'rmse_validation': [], 'rmse_train': [], 'BIC': [], 'n_parameters': [],\n",
    "                       'n_nonzero_parameters': []}\n",
    "file = open(save_file_pair_cutoffs, 'r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    df2[values[0]]['c2'].append(float(values[4]))\n",
    "    df2[values[0]]['rmse_validation'].append(float(values[5]))\n",
    "    df2[values[0]]['rmse_train'].append(float(values[6]))\n",
    "    df2[values[0]]['BIC'].append(float(values[7]))\n",
    "    df2[values[0]]['n_parameters'].append(float(values[8]))\n",
    "    df2[values[0]]['n_nonzero_parameters'].append(float(values[9]))\n",
    "\n",
    "for fit_method in fit_methods_all:\n",
    "    df2[fit_method] = pd.DataFrame(df2[fit_method])\n",
    "    best_cutoffs2[fit_method] = df2[fit_method].c2[df2[fit_method].rmse_validation.idxmin()]\n",
    "\n",
    "save_file_best_cutoffs = prevent_override(save_file_best_cutoffs)\n",
    "file = open(save_file_best_cutoffs, 'w')\n",
    "file_format = '%14s,\\t%13s' + os.linesep\n",
    "file.write(file_format % ('fit_method', 'cutoff2'))\n",
    "for key, cutoff in best_cutoffs2.items():\n",
    "    file.write(file_format % (key, cutoff))\n",
    "file.close()\n",
    "max_cutoff2 = max(best_cutoffs2.values())\n",
    "print('Max pair cutoff: %s' % max_cutoff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e9e504e7122b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:02:13.004434Z",
     "start_time": "2025-03-06T17:03:01.004586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing structure 0 of 1017 (0.0%)   2025-03-17 16:18:18.717381\n",
      "Computing structure 101 of 1017 (9.9%)   2025-03-17 16:18:19.317517\n",
      "Computing structure 202 of 1017 (19.9%)   2025-03-17 16:18:20.082550\n",
      "Computing structure 303 of 1017 (29.8%)   2025-03-17 16:18:20.851879\n",
      "Computing structure 404 of 1017 (39.7%)   2025-03-17 16:18:21.633892\n",
      "Computing structure 505 of 1017 (49.7%)   2025-03-17 16:18:22.420601\n",
      "Computing structure 606 of 1017 (59.6%)   2025-03-17 16:18:23.532772\n",
      "Computing structure 707 of 1017 (69.5%)   2025-03-17 16:18:24.640160\n",
      "Computing structure 808 of 1017 (79.4%)   2025-03-17 16:18:32.224290\n",
      "Computing structure 909 of 1017 (89.4%)   2025-03-17 16:18:39.523876\n",
      "Computing structure 1010 of 1017 (99.3%)   2025-03-17 16:18:46.805663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Condition number is large, 1.0144327346680848e+17\n",
      "Condition number is large, 7.940692350958742e+16\n",
      "Condition number is large, 8.307753651835523e+16\n",
      "Condition number is large, 8.437987610926011e+16\n",
      "Condition number is large, 9.07517304714622e+16\n",
      "Condition number is large, 6.851444652929641e+16\n",
      "Condition number is large, 7.378980521528547e+16\n",
      "Condition number is large, 8.807032314879656e+16\n",
      "Condition number is large, 6.693536468912453e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(cs) = 34\n",
      "starting validation with ardr-lambda algorithm  2025-03-17 16:18:47.276028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Condition number is large, 7.834854405400144e+16\n",
      "Condition number is large, 7.26134940038067e+16\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CrossValidationEstimator' object is not a mapping",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m\n\u001b[1;32m     19\u001b[0m     cutoffs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m c3\n\u001b[1;32m     20\u001b[0m cve \u001b[38;5;241m=\u001b[39m train_ce(prim\u001b[38;5;241m=\u001b[39mprim_TS,\n\u001b[1;32m     21\u001b[0m                chemical_symbols\u001b[38;5;241m=\u001b[39mchemical_symbols_TS,\n\u001b[1;32m     22\u001b[0m                cutoffs\u001b[38;5;241m=\u001b[39mcutoffs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m                tol_positions\u001b[38;5;241m=\u001b[39mtol_positions,\n\u001b[1;32m     29\u001b[0m                fit_method\u001b[38;5;241m=\u001b[39mfit_method)\n\u001b[0;32m---> 30\u001b[0m records[fit_method]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc3\u001b[39m\u001b[38;5;124m'\u001b[39m: c3, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcve})\n\u001b[1;32m     32\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(save_file_triplet_cutoffs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m file\u001b[38;5;241m.\u001b[39mwrite(file_format \u001b[38;5;241m%\u001b[39m (fit_method, cutoffs, c3, cve\u001b[38;5;241m.\u001b[39mrmse_validation, cve\u001b[38;5;241m.\u001b[39mrmse_train, cve\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mBIC, cve\u001b[38;5;241m.\u001b[39mn_parameters, cve\u001b[38;5;241m.\u001b[39mn_nonzero_parameters, pytime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CrossValidationEstimator' object is not a mapping"
     ]
    }
   ],
   "source": [
    "# c3_vals = cutoff_vals[0: biggest min(rmse_validation) cutoff2]\n",
    "# changed to 10 since everything above 8.09=cutoff_vals[9]\n",
    "save_file_triplet_cutoffs = prevent_override(save_file_triplet_cutoffs)\n",
    "file = open(save_file_triplet_cutoffs, 'w')\n",
    "file_format = '%14s,\\t%20s,\\t%13s,\\t%15s,\\t%15s,\\t%15s,\\t%7s,\\t%7s,\\t%7s' + os.linesep\n",
    "file.write(file_format % ('fit_method','cutoffs', 'cutoff3', 'validation', 'train', 'BIC', 'number', 'nonzero','time'))\n",
    "file.close()\n",
    "c3_vals = cutoff_vals\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method] = []\n",
    "    #c3_opt_noTS_index = cutoff_vals.index(best_cutoffs_noTS[fit_method][1])\n",
    "    for c3 in c3_vals:\n",
    "        #c2TS from here\n",
    "        start_time = pytime.time()\n",
    "        cutoffs = best_cutoffs_noTS[fit_method].copy()\n",
    "        cutoffs[0] = best_cutoffs2[fit_method] #best Parameter for all useful C2-jochen-data\n",
    "        cutoffs[1] = c3\n",
    "        if c3 < cutoffs[2]:\n",
    "            cutoffs[2] = c3\n",
    "        cve = train_ce(prim=prim_TS,\n",
    "                       chemical_symbols=chemical_symbols_TS,\n",
    "                       cutoffs=cutoffs,\n",
    "                       energy_list=train_H_o_M,\n",
    "                       atoms_ref_list=train_structures,\n",
    "                       outcar_list=file_location,\n",
    "                       position_tolerance=position_tolerance,\n",
    "                       symprec=symprec,\n",
    "                       tol_positions=tol_positions,\n",
    "                       fit_method=fit_method)\n",
    "        records[fit_method].append({\n",
    "            'c3': c3,\n",
    "            'rmse_validation': cve.rmse_validation,\n",
    "            'rmse_train': cve.rmse_train,\n",
    "            'BIC': cve.model.BIC,\n",
    "            'n_parameters': cve.n_parameters,\n",
    "            'n_nonzero_parameters': cve.n_nonzero_parameters\n",
    "        })\n",
    "\n",
    "        file = open(save_file_triplet_cutoffs, 'a')\n",
    "        file.write(file_format % (fit_method, cutoffs, c3, cve.rmse_validation, cve.rmse_train, cve.model.BIC, cve.n_parameters, cve.n_nonzero_parameters, pytime.time()-start_time))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c15628bd2cb6a",
   "metadata": {},
   "source": [
    "### quartett cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a04336699778887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:02:13.105816Z",
     "start_time": "2025-03-06T18:02:13.103842Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cutoff_vals = [2.84, 2.85, 4.93, 5.00, 5.69, 5.75, 6.42, 7.53, 7.57, 8.09] # till 8.09 - biggest cutoff so the transition stated does not see itself\n",
    "# \n",
    "position_tolerance = 0.01\n",
    "symprec = 0.01\n",
    "tol_positions=0.05\n",
    "\n",
    "fit_methods = ['lasso', 'least-squares', 'bayesian-ridge', 'omp', 'ridge', 'split-bregman', 'elasticnet', 'ardr-lineScan']\n",
    "#'ardr-lambda', 'rfe', \n",
    "\n",
    "save_file_triplet_cutoffs = '/nfshome/winkelmann/ARL/tmp/cutoffs_3_anchor_fit'\n",
    "save_file_quartet_cutoffs = '/nfshome/winkelmann/ARL/tmp/cutoffs_4_anchor_fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c566aa76632db94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:02:13.136190Z",
     "start_time": "2025-03-06T18:02:13.125028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max triplet cutoff: 8.09\n"
     ]
    }
   ],
   "source": [
    "# read results cutoff3\n",
    "\n",
    "best_cutoffs3 = {}\n",
    "df3 = {}\n",
    "\n",
    "for fit_method in fit_methods_all:\n",
    "    df3[fit_method] = {'c3': [], 'rmse_validation': [], 'rmse_train': [], 'BIC': [], 'n_parameters': [],\n",
    "                       'n_nonzero_parameters': []}\n",
    "file = open(save_file_triplet_cutoffs,'r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    df3[values[0]]['c3'].append(float(values[4]))\n",
    "    df3[values[0]]['rmse_validation'].append(float(values[5]))\n",
    "    df3[values[0]]['rmse_train'].append(float(values[6]))\n",
    "    df3[values[0]]['BIC'].append(float(values[7]))\n",
    "    df3[values[0]]['n_parameters'].append(float(values[8]))\n",
    "    df3[values[0]]['n_nonzero_parameters'].append(float(values[9]))\n",
    "\n",
    "for fit_method in fit_methods_all:\n",
    "    df3[fit_method] = pd.DataFrame(df3[fit_method])\n",
    "    best_cutoffs3[fit_method] = df3[fit_method].c3[df3[fit_method].rmse_validation.idxmin()]\n",
    "\n",
    "#append best cutoffs save file\n",
    "file = open(save_file_best_cutoffs, 'r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "line0 = lines[0].replace(' ', '').split(',')\n",
    "file.close()\n",
    "if(len(line0) > 2):\n",
    "    save_file_best_cutoffs = prevent_override(save_file_best_cutoffs)\n",
    "file = open(save_file_best_cutoffs, 'w')\n",
    "file_format = '%14s,\\t%13s,\\t%13s' + os.linesep\n",
    "file.write(file_format % ('fit_method', 'cutoff2', 'cutoff3'))\n",
    "for key,cutoff in best_cutoffs3.items():\n",
    "    file.write(file_format %(key,best_cutoffs2[key], cutoff))\n",
    "file.close()\n",
    "max_cutoff3 = max(best_cutoffs3.values())\n",
    "print('Max triplet cutoff: %s' % max_cutoff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83e1e1d5536e2715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T20:26:02.954568Z",
     "start_time": "2025-03-06T18:46:25.141784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " fit_method: lasso\n",
      "lasso with cutoffs: [8.09, 8.09, 2.84] started at 2025-03-17 17:38:09.182622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     25\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m         cve \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprim_TS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mchemical_symbols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchemical_symbols_TS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcutoffs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoffs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                    \u001b[49m\u001b[43menergy_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_H_o_M\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43matoms_ref_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_structures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutcar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mposition_tolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msymprec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymprec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtol_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol_positions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfit_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;66;03m#\\33[<style>m is the ANSI escape code for color and style\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maborted due to error \u001b[39m\u001b[38;5;130;01m\\33\u001b[39;00m\u001b[38;5;124m[41m Error:\u001b[39m\u001b[38;5;130;01m\\33\u001b[39;00m\u001b[38;5;124m[0m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\33\u001b[39;00m\u001b[38;5;124m[45m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\33\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 101\u001b[0m, in \u001b[0;36mtrain_ce\u001b[0;34m(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions, fit_method)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_ce\u001b[39m(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions, fit_method):\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    Train a cluster expansion with the given cutoffs and return fit metrics of the obtained model.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    prim: ase atoms object, its the primitive structure that the CE lives on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m        fit_method='least-squares'\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     (A, y), mapped_structures \u001b[38;5;241m=\u001b[39m \u001b[43mget_fit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchemical_symbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menergy_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matoms_ref_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_tolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mardr-lambda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[25], line 40\u001b[0m, in \u001b[0;36mget_fit_data\u001b[0;34m(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (outcar, E, at_ref) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(outcar_list, energy_list, atoms_ref_list)):\n\u001b[1;32m     28\u001b[0m     \n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# print update of training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Map the enumerated structure to the primitive cell, add it to cluster space with the energy of the properly relaxed system\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m         mapped_atoms, info \u001b[38;5;241m=\u001b[39m \u001b[43micet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure_to_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mat_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43minert_species\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mtol_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43massume_no_cell_relaxation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m         mapped_structures\u001b[38;5;241m.\u001b[39mappend(mapped_atoms)\n\u001b[1;32m     48\u001b[0m         sc\u001b[38;5;241m.\u001b[39madd_structure(structure\u001b[38;5;241m=\u001b[39mmapped_atoms,\n\u001b[1;32m     49\u001b[0m                  properties\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Energy\u001b[39m\u001b[38;5;124m'\u001b[39m: E},\n\u001b[1;32m     50\u001b[0m                  user_tag \u001b[38;5;241m=\u001b[39m outcar,\n\u001b[1;32m     51\u001b[0m                  sanity_check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m                  )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/icet/tools/structure_mapping.py:133\u001b[0m, in \u001b[0;36mmap_structure_to_reference\u001b[0;34m(structure, reference, inert_species, tol_positions, suppress_warnings, assume_no_cell_relaxation)\u001b[0m\n\u001b[1;32m    130\u001b[0m structure_scaled\u001b[38;5;241m.\u001b[39mset_cell(reference_supercell\u001b[38;5;241m.\u001b[39mcell, scale_atoms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Match positions\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m mapped_structure, drmax, dravg, warning \u001b[38;5;241m=\u001b[39m \u001b[43m_match_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mreference_supercell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m warning:\n\u001b[1;32m    137\u001b[0m     warnings \u001b[38;5;241m=\u001b[39m [warning]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/icet/tools/structure_mapping.py:331\u001b[0m, in \u001b[0;36m_match_positions\u001b[0;34m(structure, reference)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     atom\u001b[38;5;241m.\u001b[39msymbol \u001b[38;5;241m=\u001b[39m structure[j]\u001b[38;5;241m.\u001b[39msymbol\n\u001b[0;32m--> 331\u001b[0m     dvecs, drs \u001b[38;5;241m=\u001b[39m \u001b[43mget_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m                               \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     displacement_magnitudes\u001b[38;5;241m.\u001b[39mappend(drs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    335\u001b[0m     displacements\u001b[38;5;241m.\u001b[39mappend(dvecs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ase/geometry/geometry.py:383\u001b[0m, in \u001b[0;36mget_distances\u001b[0;34m(p1, p2, cell, pbc)\u001b[0m\n\u001b[1;32m    380\u001b[0m     p2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(p2)\n\u001b[1;32m    381\u001b[0m     D \u001b[38;5;241m=\u001b[39m (p2[np\u001b[38;5;241m.\u001b[39mnewaxis, :, :] \u001b[38;5;241m-\u001b[39m p1[:, np\u001b[38;5;241m.\u001b[39mnewaxis, :])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m--> 383\u001b[0m (D, ), (D_len, ) \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_find_mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mD\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     Dout \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((np1, np1, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ase/geometry/geometry.py:242\u001b[0m, in \u001b[0;36mconditional_find_mic\u001b[0;34m(vectors, cell, pbc)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell or pbc must be both set or both be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     mics \u001b[38;5;241m=\u001b[39m [find_mic(v, cell, pbc) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vectors]\n\u001b[1;32m    243\u001b[0m     vectors, vector_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mmics)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ase/geometry/geometry.py:242\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell or pbc must be both set or both be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     mics \u001b[38;5;241m=\u001b[39m [\u001b[43mfind_mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vectors]\n\u001b[1;32m    243\u001b[0m     vectors, vector_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mmics)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ase/geometry/geometry.py:217\u001b[0m, in \u001b[0;36mfind_mic\u001b[0;34m(v, cell, pbc)\u001b[0m\n\u001b[1;32m    215\u001b[0m naive_find_mic_is_safe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     vmin, vlen \u001b[38;5;241m=\u001b[39m \u001b[43mnaive_find_mic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# naive find mic is safe only for the following condition\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (vlen \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmin\u001b[39m(cell\u001b[38;5;241m.\u001b[39mlengths()))\u001b[38;5;241m.\u001b[39mall():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ase/geometry/geometry.py:166\u001b[0m, in \u001b[0;36mnaive_find_mic\u001b[0;34m(v, cell)\u001b[0m\n\u001b[1;32m    164\u001b[0m f \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(f \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    165\u001b[0m vmin \u001b[38;5;241m=\u001b[39m f \u001b[38;5;241m@\u001b[39m cell\n\u001b[0;32m--> 166\u001b[0m vlen \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vmin, vlen\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/linalg/linalg.py:2379\u001b[0m, in \u001b[0;36m_norm_dispatcher\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2375\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(svd(y, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 2379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_norm_dispatcher\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x,)\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnorm\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# c4_vals = cutoff_vals[0: biggest min(rmse_validation) cutoff3]\n",
    "# changed to 10 since everything above 8.09=cutoff_vals[9]\n",
    "save_file_quartet_cutoffs = prevent_override(save_file_quartet_cutoffs)\n",
    "file = open(save_file_quartet_cutoffs, 'w')\n",
    "file_format = '%14s,\\t%20s,\\t%13s,\\t%15s,\\t%15s,\\t%15s,\\t%7s,\\t%7s,\\t%7s' + os.linesep\n",
    "file.write(file_format % ('fit_method','cutoffs', 'cutoff4', 'validation', 'train', 'BIC', 'number', 'nonzero','time'))\n",
    "file.close()\n",
    "for fit_method in fit_methods:\n",
    "    print(f'\\n fit_method: {fit_method}')\n",
    "    records[fit_method] = []\n",
    "    c4_vals = cutoff_vals\n",
    "    for c4 in c4_vals:\n",
    "        #c2TS from here\n",
    "        start_time = pytime.time()\n",
    "        cutoffs = []\n",
    "        cutoffs.append(best_cutoffs2[fit_method]) #best Parameter for all useful C2-jochen-data\n",
    "        cutoffs.append(best_cutoffs3[fit_method]) #best Parameter for all useful C3-jochen-data\n",
    "        cutoffs.append(c4)\n",
    "        if c4 > cutoffs[1]:\n",
    "            print(f'stopped {fit_method} since c3 limit was reached at {c4}')\n",
    "            break\n",
    "        print(f'{fit_method} with cutoffs: {cutoffs} started at {datetime.datetime.now()}')\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('once')\n",
    "                cve = train_ce(prim=prim_TS,\n",
    "                            chemical_symbols=chemical_symbols_TS,\n",
    "                            cutoffs=cutoffs,\n",
    "                            energy_list=train_H_o_M,\n",
    "                            atoms_ref_list=train_structures,\n",
    "                            outcar_list=file_location,\n",
    "                            position_tolerance=position_tolerance,\n",
    "                            symprec=symprec,\n",
    "                            tol_positions=tol_positions,\n",
    "                            fit_method=fit_method)\n",
    "        except Exception as e: #\\33[<style>m is the ANSI escape code for color and style\n",
    "            print(f'aborted due to error \\33[41m Error:\\33[0m \\n \\t \\33[45m{e} \\33[0m')\n",
    "            continue\n",
    "        records[fit_method].append({\n",
    "            'c4': c4,\n",
    "            'rmse_validation': cve.rmse_validation,\n",
    "            'rmse_train': cve.rmse_train,\n",
    "            'BIC': cve.model.BIC,\n",
    "            'n_parameters': cve.n_parameters,\n",
    "            'n_nonzero_parameters': cve.n_nonzero_parameters\n",
    "        })\n",
    "\n",
    "        file = open(save_file_quartet_cutoffs, 'a')\n",
    "        file.write(file_format % (fit_method, cutoffs, c4, cve.rmse_validation, cve.rmse_train, cve.model.BIC, cve.n_parameters, cve.n_nonzero_parameters, pytime.time()-start_time))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0c4267425bdb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fit_method \u001b[38;5;129;01min\u001b[39;00m fit_methods_all:\n\u001b[1;32m     24\u001b[0m     df4[fit_method] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df4[fit_method])\n\u001b[0;32m---> 25\u001b[0m     best_cutoffs4[fit_method] \u001b[38;5;241m=\u001b[39m df4[fit_method]\u001b[38;5;241m.\u001b[39mc4[\u001b[43mdf4\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfit_method\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse_validation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midxmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     27\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(save_file_best_cutoffs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m file\u001b[38;5;241m.\u001b[39mreadline()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:2334\u001b[0m, in \u001b[0;36mSeries.idxmin\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21midxmin\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;124;03m    Return the row label of the minimum value.\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2332\u001b[0m \u001b[38;5;124;03m    nan\u001b[39;00m\n\u001b[1;32m   2333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2334\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/base.py:719\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmin\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmin()\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[int, ndarray]\", expected\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# \"int\")\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanargmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/nanops.py:1142\u001b[0m, in \u001b[0;36mnanargmin\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m   1140\u001b[0m values, mask, _, _, _ \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[0;32m-> 1142\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "# write overall best cutoff results\n",
    "\n",
    "best_cutoffs4 = {}\n",
    "df4 = {}\n",
    "\n",
    "for fit_method in fit_methods_all:\n",
    "    df4[fit_method] = {'c4': [], 'rmse_validation': [], 'rmse_train': [], 'BIC': [], 'n_parameters': [],\n",
    "                       'n_nonzero_parameters': []}\n",
    "file = open(save_file_quartet_cutoffs,'r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    df4[values[0]]['c4'].append(float(values[4]))\n",
    "    df4[values[0]]['rmse_validation'].append(float(values[5]))\n",
    "    df4[values[0]]['rmse_train'].append(float(values[6]))\n",
    "    df4[values[0]]['BIC'].append(float(values[7]))\n",
    "    df4[values[0]]['n_parameters'].append(float(values[8]))\n",
    "    df4[values[0]]['n_nonzero_parameters'].append(float(values[9]))\n",
    "\n",
    "for fit_method in fit_methods_all:\n",
    "    df4[fit_method] = pd.DataFrame(df4[fit_method])\n",
    "    best_cutoffs4[fit_method] = df4[fit_method].c4[df4[fit_method].rmse_validation.idxmin()]\n",
    "\n",
    "file = open(save_file_best_cutoffs, 'r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "line0 = lines[0].replace(' ', '').split(',')\n",
    "file.close()\n",
    "if (len(line0) > 3):\n",
    "    save_file_best_cutoffs = prevent_override(save_file_best_cutoffs)\n",
    "file = open(save_file_best_cutoffs, 'w')\n",
    "file_format = '%14s,\\t%13s,\\t%13s,\\t%13s,\\t%13s' + os.linesep\n",
    "file.write(file_format % ('fit_method', 'cutoff2', 'cutoff3', 'cutoff4', 'RMSE'))\n",
    "for key, cutoff in best_cutoffs4.items():\n",
    "    file.write(file_format % (key, best_cutoffs2[key], best_cutoffs3[key], cutoff, df4[key].rmse_validation.min()))\n",
    "file.close()\n",
    "max_cutoff4 = max(best_cutoffs4.values())\n",
    "print('Max quartet cutoff: %s' % max_cutoff4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4108e",
   "metadata": {},
   "source": [
    "### creating Cluster_Expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d89c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {}\n",
    "rmses = []\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method] = []\n",
    "    start_time = pytime.time()\n",
    "    cutoffs = []\n",
    "    cutoffs.append(best_cutoffs2[fit_method]) #best Parameter for all useful C2-jochen-data\n",
    "    cutoffs.append(best_cutoffs3[fit_method]) #best Parameter for all useful C3-jochen-data\n",
    "    cutoffs.append(best_cutoffs4[fit_method]) #best Parameter for all useful C4-jochen-data\n",
    "    cve = train_ce(prim=prim_TS,\n",
    "                    chemical_symbols=chemical_symbols_TS,\n",
    "                    cutoffs=cutoffs,\n",
    "                    energy_list=train_H_o_M,\n",
    "                    atoms_ref_list=train_structures,\n",
    "                    outcar_list=file_location,\n",
    "                    position_tolerance=position_tolerance,\n",
    "                    symprec=symprec,\n",
    "                    tol_positions=tol_positions,\n",
    "                    fit_method=fit_method)\n",
    "    records[fit_method].append({'c4': cve})\n",
    "    rmses.append(cve.rmse_validation)\n",
    "\n",
    "    cs = ClusterSpace(structure=prim_TS,\n",
    "                    cutoffs=cutoffs,\n",
    "                    chemical_symbols=chemical_symbols_TS,\n",
    "                    position_tolerance=position_tolerance,\n",
    "                    symprec=symprec)\n",
    "    \n",
    "    ce = ClusterExpansion(cluster_space=cs, parameters=records[fit_method].parameters, metadata=records[fit_method].summary)\n",
    "    ce.write(f'/nfshome/winkelmann/ARL/tmp/mixing_energy_anchorTS_{fit_method}.ce')\n",
    "    print(f'wrote {fit_method} with RMSE: {cve[\"rmse_validation\"]}')\n",
    "print(f'\\n best RMSE: {min(rmses)} with {fit_methods[rmses.index(min(rmses))]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9210e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing structure 0 of 1017 (0.0%)   2025-03-07 19:28:10.529276\n",
      "Computing structure 101 of 1017 (9.9%)   2025-03-07 19:28:11.656842\n",
      "Computing structure 202 of 1017 (19.9%)   2025-03-07 19:28:13.339000\n",
      "Computing structure 303 of 1017 (29.8%)   2025-03-07 19:28:14.934450\n",
      "Computing structure 404 of 1017 (39.7%)   2025-03-07 19:28:16.618606\n",
      "Computing structure 505 of 1017 (49.7%)   2025-03-07 19:28:18.271099\n",
      "Computing structure 606 of 1017 (59.6%)   2025-03-07 19:28:20.561337\n",
      "Computing structure 707 of 1017 (69.5%)   2025-03-07 19:28:22.698728\n",
      "Computing structure 808 of 1017 (79.4%)   2025-03-07 19:28:31.946124\n",
      "Computing structure 909 of 1017 (89.4%)   2025-03-07 19:28:41.188438\n",
      "Computing structure 1010 of 1017 (99.3%)   2025-03-07 19:28:50.601959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Condition number is large, 1.356769859805456e+18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(cs) = 722\n",
      "starting validation with ardr-lambda algorithm  2025-03-07 19:28:51.212155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Condition number is large, 1.3501540529628426e+18\n",
      "Condition number is large, 1.4280541635527785e+18\n",
      "Condition number is large, 1.420193937092085e+18\n",
      "Condition number is large, 1.3986816282814356e+18\n",
      "Condition number is large, 1.3170895185441178e+18\n",
      "Condition number is large, 1.4280151380585766e+18\n",
      "Condition number is large, 1.4590739241633966e+18\n",
      "Condition number is large, 1.3623682938152796e+18\n",
      "Condition number is large, 1.4952573266722368e+18\n",
      "Condition number is large, 9.501693419616951e+17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote ardr-lambda with RMSE: 0.002260302424987309\n"
     ]
    }
   ],
   "source": [
    "fit_method = 'ardr-lambda'\n",
    "rmses = []\n",
    "records[fit_method] = {}\n",
    "start_time = pytime.time()\n",
    "cutoffs = []\n",
    "cutoffs.append(8.09) #best Parameter for all useful C2-jochen-data\n",
    "cutoffs.append(6.42) #best Parameter for all useful C3-jochen-data\n",
    "cutoffs.append(6.42) #best Parameter for all useful C4-jochen-data\n",
    "cve = train_ce(prim=prim_TS,\n",
    "                chemical_symbols=chemical_symbols_TS,\n",
    "                cutoffs=cutoffs,\n",
    "                energy_list=train_H_o_M,\n",
    "                atoms_ref_list=train_structures,\n",
    "                outcar_list=file_location,\n",
    "                position_tolerance=position_tolerance,\n",
    "                symprec=symprec,\n",
    "                tol_positions=tol_positions,\n",
    "                fit_method=fit_method)\n",
    "rmses.append(cve.rmse_validation)\n",
    "\n",
    "cs = ClusterSpace(structure=prim_TS,\n",
    "                cutoffs=cutoffs,\n",
    "                chemical_symbols=chemical_symbols_TS,\n",
    "                position_tolerance=position_tolerance,\n",
    "                symprec=symprec)\n",
    "\n",
    "ce = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce.write(f'/nfshome/winkelmann/ARL/tmp/mixing_energy_anchorTS_{fit_method}.ce')\n",
    "print(f'wrote {fit_method} with RMSE: {rmses[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4353564b1b266",
   "metadata": {},
   "source": [
    "evtl auch schon alter rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fddafe23e7ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4_vals = cutoff_vals[0: biggest min(rmse_validation) cutoff3]\n",
    "\n",
    "save_file_pair_cutoffs = prevent_override('/nfshome/winkelmann/ARL/tmp/cutoff_4_jochen_fit')\n",
    "file_format = '%14s,\\t%13s,\\t%13s,\\t%15s,\\t%15s,\\t%15s,\\t%7s,\\t%7s,\\t%7s' + os.linesep\n",
    "file = open(save_file_pair_cutoffs, 'w')\n",
    "file.write(file_format % ('fit_method','cutoff3', 'cutoff4', 'validation', 'train', 'BIC', 'number', 'nonzero','time'))\n",
    "file.close()\n",
    "c4_vals = cutoff_vals\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method] = {'8.09':[],\n",
    "                           '6.42':[]}\n",
    "    for key in records[fit_method].keys():\n",
    "\n",
    "        for c4 in c4_vals: \n",
    "            #c2TS c3TS from here\n",
    "            if (c4 > float(key)):\n",
    "                continue\n",
    "            start_time = pytime.time()\n",
    "            cutoffs = [8.09, float(key), c4]\n",
    "            cve = train_ce(prim=prim_TS,\n",
    "                           chemical_symbols=chemical_symbols_TS,\n",
    "                           cutoffs=cutoffs,\n",
    "                           energy_list=train_H_o_M,\n",
    "                           atoms_ref_list=train_structures,\n",
    "                           outcar_list=file_location,\n",
    "                           position_tolerance=position_tolerance,\n",
    "                           symprec=symprec,\n",
    "                           tol_positions=tol_positions,\n",
    "                           fit_method=fit_method)\n",
    "            records[fit_method][key].append({'key': float(key), **cve})\n",
    "    \n",
    "            file = open(save_file_pair_cutoffs, 'a')\n",
    "            file.write(file_format % (fit_method, key, c4, cve['rmse_validation'], cve['rmse_train'], cve['BIC'], cve['n_parameters'],cve['n_nonzero_parameters'], pytime.time()-start_time))\n",
    "             file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
