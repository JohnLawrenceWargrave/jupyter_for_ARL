{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b318c02-42e3-4202-8407-0140530dd681",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7b666-1d2f-49c1-8d52-03ffb5d64913",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "id": "74224aca-eb1f-48cc-916a-c9a0daebe569",
   "metadata": {},
   "source": [
    "# Modules are available in conda environment with name: icet\n",
    "# conda activate icet\n",
    "\n",
    "import ase\n",
    "from ase.io import read as ASEread\n",
    "from ase.io.vasp import write_vasp\n",
    "from ase.db import connect\n",
    "from ase.cell import Cell\n",
    "from ase.neighborlist import NewPrimitiveNeighborList\n",
    "from ase.build import make_supercell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import colormaps\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import icet\n",
    "from icet import ClusterSpace, StructureContainer, ClusterExpansion\n",
    "from trainstation import CrossValidationEstimator\n",
    "from icet.tools import enumerate_structures\n",
    "from icet.tools.structure_generation import generate_sqs_by_enumeration\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_context('notebook')\n",
    "except ImportError:\n",
    "    print('sad')\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cf5c6698-284f-4520-8ec0-3e37dd2530be",
   "metadata": {},
   "source": [
    "## Misc Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "eccef56b-63c3-4529-b4c1-26fc2b37ad25",
   "metadata": {},
   "source": [
    "# Stop message\n",
    "def jupyter_stop(ErrorMessage=\"User-defined stop via jupyter_stop() function\"):\n",
    "    \"\"\"\n",
    "    User defined stop function, similar to exit(). Mostly for testing purpose or to \n",
    "    avoid overwriting of already generated data.\n",
    "    \"\"\"\n",
    "    raise SystemExit(ErrorMessage)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "72ad42dd-452a-4452-b4e9-bc191ce9eba9",
   "metadata": {},
   "source": [
    "## CE Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36111f-9653-4981-8db5-00753bce4ea3",
   "metadata": {},
   "source": [
    "## Reorder Atoms"
   ]
  },
  {
   "cell_type": "code",
   "id": "abe734d9-04a2-422d-89fd-fd08eab2bee5",
   "metadata": {},
   "source": [
    "# S only in this list to 'trick' the structure enumeration\n",
    "# S as extra Nickel\n",
    "atomic_label2number = {\"Li\" :  3,\n",
    "                       \"O\"  :  8,\n",
    "                       \"S\"  : 16,\n",
    "                       \"Ni\" : 28}\n",
    "\n",
    "atomic_number2label = { 3 : \"Li\",\n",
    "                        8 :  \"O\",\n",
    "                       16 :  \"S\",\n",
    "                       28 :  \"Ni\"}\n",
    "\n",
    "\n",
    "def order_atoms(atoms,order=[\"Li\",\"Ni\",\"O\"]):\n",
    "    \n",
    "    # get old positions and atomic numbers\n",
    "    old_positions       = atoms.get_positions()\n",
    "    old_atomic_number   = atoms.get_atomic_numbers()\n",
    "    \n",
    "    # create empty dict for all types\n",
    "    atomic_pos_dict = {}\n",
    "    for sym in order:\n",
    "        atomic_pos_dict[sym] = []\n",
    "    \n",
    "    # append positions to dict \n",
    "    for num, pos in zip(old_atomic_number, old_positions):\n",
    "        atomic_pos_dict[atomic_number2label[num]].append(pos)\n",
    "    \n",
    "    # put together the new ordered positions and atomic numbers\n",
    "    new_positions = []\n",
    "    new_atomic_numbers = []\n",
    "    for sym in order:\n",
    "        new_positions.extend(atomic_pos_dict[sym])\n",
    "        new_atomic_numbers.extend( [ atomic_label2number[sym] ] * len(atomic_pos_dict[sym]) )\n",
    "    \n",
    "    # copy original atoms object and modify it\n",
    "    copy_atoms = atoms.copy()\n",
    "    copy_atoms.set_positions(new_positions)\n",
    "    copy_atoms.set_atomic_numbers(new_atomic_numbers)\n",
    "    \n",
    "    return copy_atoms\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef5b8a37-f885-48e3-8f5f-1db44c0663da",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "id": "967ec400-e11b-49cc-b5f3-0467234e6013",
   "metadata": {},
   "source": [
    "### Get the reference energies of LiNiO2 and NiO2 normed per unit cell\n",
    "LiNiO2 = ASEread(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/02_enumerate_P21c_0-4fu/0001_finished_approved/run_final_approved/OUTCAR\")\n",
    "E_ref_LiNiO2_per_O2 = LiNiO2.get_potential_energy() / LiNiO2.get_chemical_symbols().count(\"O\") * 2 #or per Ni in case of no extra Ni\n",
    "\n",
    "NiO2   = ASEread(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/02_enumerate_P21c_0-4fu/0003_finished_approved/run_final_approved/OUTCAR\")\n",
    "E_ref_NiO2_per_O2   = NiO2.get_potential_energy() / NiO2.get_chemical_symbols().count(\"O\") * 2 #or per Ni in case of no extra Ni"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "961a39b7-9176-4e06-9a47-475963e8839b",
   "metadata": {},
   "source": [
    "## Own enumerated structures based on P21/c"
   ]
  },
  {
   "cell_type": "code",
   "id": "4eab6429-e300-41d3-8141-6846d035a46c",
   "metadata": {},
   "source": [
    "#Li verteilung ohne trans\n",
    "atoms_for_training_from_own_enumerated_structures = []\n",
    "H_o_M_for_training_from_own_enumerated_structures = []\n",
    "\n",
    "# Get all the outcars of interest\n",
    "outcars_for_training_from_own_enumerated_structures= sorted(glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/02_enumerate_P21c_0-4fu/0*_finished_approved/run_final_approved/OUTCAR\"))\n",
    "\n",
    "# Iterate over them\n",
    "for outcar in outcars_for_training_from_own_enumerated_structures:\n",
    "    \n",
    "    # get atoms object\n",
    "    atoms = ASEread(outcar, index=\":\")\n",
    "    \n",
    "    # Compute total heat of mixing \n",
    "    Li_count = atoms[-1].get_chemical_symbols().count(\"Li\")\n",
    "    O_count  = atoms[-1].get_chemical_symbols().count(\"O\")\n",
    "    H_o_M    = atoms[-1].get_potential_energy() - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "\n",
    "    # Append data...     \n",
    "    # ... but to make mapping easier take the originally generated structures instead of the relaxed ones\n",
    "    ref = \"/\".join(outcar.split(\"/\")[:-2]) + \"/POSCAR_enumerated\"\n",
    "    atoms_for_training_from_own_enumerated_structures.append(ASEread(ref))\n",
    "    #refactor to HOM per Atom\n",
    "    H_o_M_for_training_from_own_enumerated_structures.append( H_o_M / len(atoms[-1]) )\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50efd88e-7c3f-416f-9e2a-4f7c6d72e639",
   "metadata": {},
   "source": [
    "## Markus low energy CE data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Basic setups\n",
    "\n",
    "def get_fit_data(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions):\n",
    "    \"\"\"\n",
    "    Construct cluster space and structure container for the given cutoffs\n",
    "    and return the fit matrix along with the target energies\n",
    "    \"\"\"\n",
    "    # stepsize to print update of training:\n",
    "    stepsize = int(0.1*len(outcar_list))\n",
    "    \n",
    "    # Collect the mapped structures\n",
    "    mapped_structures = []\n",
    "    \n",
    "    # Set up Clusterspace\n",
    "    cs = ClusterSpace(structure=prim,\n",
    "                      cutoffs=cutoffs,\n",
    "                      chemical_symbols=chemical_symbols,\n",
    "                      position_tolerance=position_tolerance,\n",
    "                      symprec=symprec)\n",
    "    \n",
    "    #print(cs)\n",
    "    \n",
    "    # Set up StructureContainer with the previsouly generated ClusterSpace\n",
    "    sc = StructureContainer(cluster_space=cs)\n",
    "    \n",
    "    # Fill the StructureContainer\n",
    "    for i, (outcar, E, at_ref) in enumerate(zip(outcar_list, energy_list, atoms_ref_list)):\n",
    "        \n",
    "        # print update of training\n",
    "        if i % stepsize == 0:\n",
    "            print(f\"Computing structure {i} of {len(outcar_list)} ({i/len(outcar_list):.1%})   {datetime.datetime.now()}\")\n",
    "        \n",
    "        \n",
    "        # Read the OUTCAR [by default last step is used] and get energy\n",
    "        #at     = ASEread(outcar)\n",
    "        #total_energy = at.get_potential_energy() # total_energy = atoms.get_potential_energy(force_consistent=True)\n",
    "        \n",
    "        # Map the enumerated structure to the primitive cell, add it to cluster space with the energy of the properly relaxed system\n",
    "        try:\n",
    "            mapped_atoms, info = icet.tools.map_structure_to_reference(structure=at_ref, \n",
    "                                                             reference=prim, \n",
    "                                                             inert_species=[\"O\"], \n",
    "                                                             tol_positions=tol_positions, \n",
    "                                                             suppress_warnings=False, \n",
    "                                                             assume_no_cell_relaxation=False)\n",
    "            mapped_structures.append(mapped_atoms)\n",
    "\n",
    "            sc.add_structure(structure=mapped_atoms,\n",
    "                     properties={'Total Energy': E},\n",
    "                     user_tag = outcar,\n",
    "                     sanity_check=True,\n",
    "                     )\n",
    "        \n",
    "        except ValueError as err:\n",
    "            print(f\"Mapping Error with {outcar}\")\n",
    "            print(f\"Note: Possibly a different structure was used for the mapping!\")\n",
    "            print(\"Original Error Message:\")\n",
    "            print(err , \"\\n\")\n",
    "            \n",
    "\n",
    "            \n",
    "    print(f\"len(cs) = {len(cs)}\")\n",
    "    \n",
    "    return sc.get_fit_data(key='Total Energy'), mapped_structures\n",
    "\n",
    "\n",
    "def get_A_y(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions):\n",
    "    return get_fit_data(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions)\n",
    "\n",
    "\n",
    "\n",
    "def get_row(cve, alpha=None):\n",
    "    row = dict()\n",
    "    row['rmse_validation'] = cve.rmse_validation\n",
    "    row['rmse_train'] = cve.rmse_train\n",
    "    row['BIC'] = cve.model.BIC\n",
    "    row['n_parameters'] = cve.n_parameters\n",
    "    row['n_nonzero_parameters'] = cve.n_nonzero_parameters\n",
    "    \n",
    "    if alpha != None:\n",
    "        row['alpha'] = alpha\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "def train_ce(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions, fit_method):\n",
    "    \"\"\"\n",
    "    Train a cluster expansion with the given cutoffs and return fit metrics of the obtained model.\n",
    "    prim: ase atoms object, its the primitive structure that the CE lives on\n",
    "    chemical_symbols: List of the possible atoms types on the different sites of prim\n",
    "    cutoffs: cutoffs for the 2-body, 3-body, ... terms\n",
    "    atoms_list: list of all the atoms objects to use for training/testing\n",
    "    outcar_list : list with paths (strings) of the corresponding atoms objects\n",
    "    fit_method examples with additional options (to be implemented at a later point): \n",
    "        fit_method='rfe'\n",
    "        fit_method='ardr', threshold_lambda=4e5\n",
    "        fit_method='ardr', line_scan=True\n",
    "        fit_method='lasso'\n",
    "        fit_method='least-squares'\n",
    "    \"\"\"\n",
    "    (A, y), mapped_structures = get_fit_data(prim, chemical_symbols, cutoffs, energy_list, atoms_ref_list, outcar_list, position_tolerance, symprec, tol_positions)\n",
    "    if fit_method == 'ardr-lambda':\n",
    "        cve = CrossValidationEstimator((A, y), fit_method='ardr', threshold_lambda=1000, validation_method='shuffle-split', n_splits=10)\n",
    "    elif fit_method == 'ardr-lineScan':\n",
    "        cve = CrossValidationEstimator((A, y), fit_method='ardr', line_scan=True, validation_method='shuffle-split', n_splits=10)\n",
    "    else:\n",
    "        cve = CrossValidationEstimator((A, y), fit_method=fit_method, validation_method='shuffle-split', n_splits=10)\n",
    "    cve.validate()\n",
    "    cve.train()\n",
    "\n",
    "    row = get_row(cve)\n",
    "    \n",
    "    return row\n",
    "\n",
    "def prevent_overwrite(file_name,add=''):\n",
    "    if os.path.exists(file_name+add):\n",
    "        if add != '':\n",
    "            n = int(add)\n",
    "            n += 1\n",
    "        else:\n",
    "            n = 1  \n",
    "        add = str(n)\n",
    "        file_name = prevent_overwrite(file_name,add)\n",
    "        add = ''\n",
    "    return file_name + add"
   ],
   "metadata": {},
   "id": "84770b26-c060-49d0-b3eb-f831bcd57ae2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "343c110c-8635-41db-baa6-d10436ebafa9",
   "metadata": {},
   "source": [
    "#Li verteilung ohne trans\n",
    "# Compare Markus last step energy and volume with the ones re-relaxed from me\n",
    "# To this end, use the README files where \n",
    "\n",
    "atoms_for_training_from_Markus_low_energy_structures   = []\n",
    "H_o_M_for_training_from_Markus_low_energy_structures   = []\n",
    "outcars_for_training_from_Markus_low_energy_structures = []\n",
    "\n",
    "READMEs = glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/CE_database_Marcel/03_Markus_approved_low_energy_data/*/README_original_path_from_Markus\")\n",
    "\n",
    "for README in READMEs:\n",
    "    \n",
    "    if os.path.isdir(README.replace(\"README_original_path_from_Markus\",\"run_final\")):\n",
    "    \n",
    "        # get the transformed CONTCAR to enable correct mapped to our prim structure later\n",
    "        # Only for the 2 structures that made problems, take the original (rotated) POSCAR to enable mapping later\n",
    "        if \"re-relax_Markus038_finished\" in README or \"re-relax_Markus115_finished\" in README:\n",
    "            with open(README, \"r\") as f:\n",
    "                line = f.readlines()[0]\n",
    "            transformed_contcar = \"/\".join(line.split(\"/\")[0:-1]) + \"/run01/POSCAR_rotated.vasp\" \n",
    "        else:\n",
    "            transformed_contcar = README.replace(\"README_original_path_from_Markus\",\"run_final/CONTCAR_rotated.vasp\")\n",
    "        atoms_transformed_contcar = ASEread(transformed_contcar)\n",
    "        atoms_for_training_from_Markus_low_energy_structures.append(atoms_transformed_contcar)\n",
    "        \n",
    "        # get the outcar from the relaxation to get the energy\n",
    "        outcar = README.replace(\"README_original_path_from_Markus\",\"run_final/OUTCAR\")\n",
    "        outcars_for_training_from_Markus_low_energy_structures.append(outcar)\n",
    "        atoms = ASEread(outcar, index=\":\")\n",
    "\n",
    "        # Compute heat of mixing and per atom\n",
    "        Li_count = atoms[-1].get_chemical_symbols().count(\"Li\")\n",
    "        O_count  = atoms[-1].get_chemical_symbols().count(\"O\")\n",
    "        H_o_M    = atoms[-1].get_potential_energy() - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2-Li_count) * E_ref_NiO2_per_O2    \n",
    "        H_o_M_for_training_from_Markus_low_energy_structures.append( H_o_M / len(atoms[-1]) )\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0fcd533b-245a-46de-b855-0f88799c0291",
   "metadata": {},
   "source": [
    "## NEB initial and final images (without Ni_Li)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6459350f-04de-4dd3-bd94-2601dd605071",
   "metadata": {},
   "source": [
    "#Li verteilung ohne trans\n",
    "atoms_for_training_NEB_initial_and_final_images = []\n",
    "H_o_M_for_training_NEB_initial_and_final_images = []\n",
    "\n",
    "# Find the ordered ones from 0250, 0500 and 0750 first\n",
    "outcars_for_training_NEB_initial_and_final_images  = glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0250/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0500/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0750/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "\n",
    "# and the ones from the random structures\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/01_initial_structure/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/02_odh/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/03_tsh/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "outcars_for_training_NEB_initial_and_final_images += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/04_double_tsh/image*/02_scan/*final/OUTCAR\", recursive=True)\n",
    "\n",
    "# Iterate over OUTCARs\n",
    "for OUTCAR in outcars_for_training_NEB_initial_and_final_images:\n",
    "    \n",
    "    # get the atoms object\n",
    "    atoms = ASEread(OUTCAR, index=\":\") \n",
    "    \n",
    "    # Compute heat of mixing and per atom\n",
    "    Li_count = atoms[-1].get_chemical_symbols().count(\"Li\")\n",
    "    O_count  = atoms[-1].get_chemical_symbols().count(\"O\")\n",
    "    H_o_M    = atoms[-1].get_potential_energy() - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "        \n",
    "    # append them to the lists\n",
    "    atoms_for_training_NEB_initial_and_final_images.append(atoms[-1])\n",
    "    H_o_M_for_training_NEB_initial_and_final_images.append( H_o_M / len(atoms[-1]) )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b01d33a1-ac96-44c4-8d1c-d0d1173c3321",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NEB transition states"
   ]
  },
  {
   "cell_type": "code",
   "id": "624b7ec2-184f-4492-93ba-b0397766787f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Li-trans\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "atoms_for_training_NEB_transition_states = []\n",
    "H_o_M_for_training_NEB_transition_states = []\n",
    "paths_for_training_NEB_transition_states = []\n",
    "\n",
    "# the ones generated manually (0250, 0500, 0750)\n",
    "paths_for_training_NEB_transition_states  = glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0250/NEB_*_finished/run_final\")\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0500/NEB_*_finished/run_final\")\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0750/NEB_*_finished/run_final\")\n",
    "\n",
    "# the random ones\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/02_odh/NEB_*/run_final\")\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/03_tsh/NEB_*/run_final\")\n",
    "paths_for_training_NEB_transition_states += glob.glob(\"/nfshome/sadowski/work/LiNiO2_data_base_Sabrina/DFT_database/NEBs_Marcel/0*random*/04_double_tsh/NEB_*/run_final\")\n",
    "\n",
    "# Iterate over all run_final folders\n",
    "for path in paths_for_training_NEB_transition_states:\n",
    "    \n",
    "    # Check the energy along the path. Use initial and final energies from the corresponding relaxed structures + the last steps of the \n",
    "    # optimized intermediate images\n",
    "    energies = []\n",
    "    energies.append(ASEread(path.replace(\"run_final\", \"OUTCAR_initial_image\")).get_potential_energy())\n",
    "    for i in [\"01\", \"02\", \"03\", \"04\", \"05\"]:\n",
    "        energies.append(ASEread(f\"{path}/{i}/OUTCAR\").get_potential_energy())\n",
    "    energies.append(ASEread(path.replace(\"run_final\", \"OUTCAR_final_image\")).get_potential_energy())\n",
    "    ax.plot([0,1,2,3,4,5,6], np.array(energies)-energies[0])\n",
    "    \n",
    "    # For \"Proper\" paths, there should be maximum in energy !between! initial and final paths... ignore those where this is not the case\n",
    "    index_highest_energy = energies.index(max(energies))\n",
    "    \n",
    "    if index_highest_energy == 0 or index_highest_energy == 6:\n",
    "        print(f\"Ignore {path}\\n  ---> image {index_highest_energy} has highest energy!\")\n",
    "    \n",
    "    else:    \n",
    "        # get the interpolated middle points of the initially created, straight odh-type path to be used as ideal position for the CE training\n",
    "        ideal_TS_structure_file = glob.glob(path.replace(\"run_final\", \"run01*/03/POSCAR_orig_linear_interpolation\"))\n",
    "        if len(ideal_TS_structure_file) == 0:                # For ODH-type jumps there is no POSCAR_orig_linear_interpolation\n",
    "            ideal_TS_structure_file = glob.glob(path.replace(\"run_final\", \"run01*/03/POSCAR\"))\n",
    "        ideal_TS_atoms = ASEread(ideal_TS_structure_file[0])\n",
    "     \n",
    "        atoms_for_training_NEB_transition_states.append(ideal_TS_atoms)\n",
    "        \n",
    "        # Compute heat of mixing per atom and append to list\n",
    "        Li_count = ideal_TS_atoms.get_chemical_symbols().count(\"Li\")\n",
    "        O_count  = ideal_TS_atoms.get_chemical_symbols().count(\"O\")\n",
    "        H_o_M    = max(energies) - Li_count * E_ref_LiNiO2_per_O2 - (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "        H_o_M_for_training_NEB_transition_states.append( H_o_M / len(ideal_TS_atoms) )\n",
    "        \n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combine data"
   ],
   "id": "9d1c549a-b563-43e4-bded-dd79ecf3b05f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combine the structures \n",
    "train_structures = ( atoms_for_training_from_own_enumerated_structures \n",
    "                    + atoms_for_training_from_Markus_low_energy_structures\n",
    "                    + atoms_for_training_NEB_initial_and_final_images \n",
    "                    #+ atoms_for_training_NEB_transition_states \n",
    "             )\n",
    "\n",
    "# ... and energies\n",
    "train_H_o_M      = ( H_o_M_for_training_from_own_enumerated_structures \n",
    "                     + H_o_M_for_training_from_Markus_low_energy_structures\n",
    "                     + H_o_M_for_training_NEB_initial_and_final_images \n",
    "                     #+ H_o_M_for_training_NEB_transition_states \n",
    "             )\n",
    "\n",
    "# to be able to retrieve problematic files, keep the paths\n",
    "file_location = ( outcars_for_training_from_own_enumerated_structures \n",
    "                + outcars_for_training_from_Markus_low_energy_structures \n",
    "                + outcars_for_training_NEB_initial_and_final_images \n",
    "                #+ paths_for_training_NEB_transition_states\n",
    "                )"
   ],
   "id": "50d64a18-03b0-4813-a70e-458e90493daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fitting of just the Li sublattice"
   ],
   "id": "6c3f94a7-ec2f-42e9-a7a1-d0f27e68fe12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read R-3m model of LiNiO2 in R-3m symmetry without transition states\n",
    "prim_without_TS = ASEread(\"/nfshome/sadowski/work/LiNiO2_Sabrina/37_CE_for_Li_diffusion/00_LNO_R-3m.vasp\")\n",
    "\n",
    "print(prim_without_TS)\n",
    "print(prim_without_TS.get_chemical_symbols())"
   ],
   "id": "ef66764f-b8d5-41a2-9ae1-46b9f526ca1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assign chemical symbols\n",
    "chemical_symbols_without_TS= [['Li', 'X'],   # Li sublattice will contain: Li and Vacancies (=X), later also Ni\n",
    "                    ['Ni'],       # Ni sublattice will not be changed\n",
    "                    ['O'],        # O  sublattice will not be changed\n",
    "                    ['O']]        "
   ],
   "id": "9d112cae-2cff-4990-ab45-82f33af23085",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<font color='red'>  deleted first fitting with CVE</font>",
   "id": "91089b061b7bfb57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color='red'> deleted traing of ardr_lambda </font>\n",
    "just left the setting of the Clusterspace"
   ],
   "id": "2e0681cf2aa6e5ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='red'> deleted code cell for calculating with the model with respect to the trained structure </font>\n",
    "kept initalization of data[] (without predicted_energy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55d50ce54a3dc25f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='red'> deleted code cell for plotting the ardr_lambda fitting vs reference data with respect to the diffrent data sets </font>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da1897762577fad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Optimizing CE"
   ],
   "id": "490d9783ea74f71c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## finding cutoffs\n",
    "list possile cutoffs and define standard variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7d2f0bce3f4e10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "c2_vals = [2.84, 2.85, 4.93, 5.00, 5.69, 5.75, 6.42, 7.53, 7.57, 8.09, 8.53, 8.57, 9.47, 9.58, 9.85, 9.89, 10.00, 10.26, 10.29, 10.39, 11.10, 11.14, 11.38, 11.50, 11.76, 11.84, 12.40, 12.42, 12.51, 12.75, 12.83, 13.03, 13.14, 13.66, 13.74, 13.96, 14.15] # 37 values - derived from list below\n",
    "\n",
    "position_tolerance = 0.01\n",
    "symprec = 0.01\n",
    "tol_positions=0.05\n",
    "\n",
    "fit_methods = ['ardr-lambda', 'ardr-lineScan', 'rfe', 'lasso', 'least-squares', 'bayesian-ridge', 'elasticnet', 'omp', 'ridge', 'split-bregman']\n",
    "records = {}"
   ],
   "id": "3e284683be5f6543",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### pair cutoff",
   "id": "36d0f678989ec493"
  },
  {
   "cell_type": "code",
   "source": [
    "jupyter_stop('dont rerun cutoff-2-scan if not necessary - needs some time')\n",
    "\n",
    "df2 = {}\n",
    "\n",
    "save_file = prevent_overwrite('/nfshome/winkelmann/ARL/tmp/cutoff_2_noTS_fit')\n",
    "file_format = '%14s,\\t%8s,\\t%15s,\\t%15s,\\t%15s,\\t%5s,\\t%5s' + os.linesep\n",
    "file = open(save_file,'w')\n",
    "file.write(file_format % ('fit_method', 'cutoff2', 'validation', 'train', 'BIC', 'number', 'nonzero'))\n",
    "file.close()\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method]= []\n",
    "    for c2 in c2_vals:       \n",
    "        cutoffs = [c2]\n",
    "        row = train_ce(prim=prim_without_TS,\n",
    "                       chemical_symbols=chemical_symbols_without_TS, \n",
    "                       cutoffs=cutoffs, \n",
    "                       energy_list = train_H_o_M, \n",
    "                       atoms_ref_list = train_structures,\n",
    "                       outcar_list = file_location, \n",
    "                       position_tolerance = position_tolerance, \n",
    "                       symprec = symprec, \n",
    "                       tol_positions = tol_positions, \n",
    "                       fit_method = fit_method)\n",
    "        records[fit_method].append({'c2': c2, **row})\n",
    "        \n",
    "        file = open(save_file,'a')\n",
    "        file.write(file_format % (fit_method, c2, row['rmse_validation'], row['rmse_train'], row['BIC'], row['n_parameters'], row['n_nonzero_parameters']))\n",
    "        file.close()\n",
    "    df2[fit_method]= pd.DataFrame(records)\n",
    "print(save_file)\n",
    "\n",
    "#Total number of Li-Li Bonds as function of cutoff (intra layer/inter layer):\n",
    "#                       same Layer          next layer x2   second next layer x2\n",
    "# 2.84    0  ( 0/ 0)    \n",
    "# 2.85    6  ( 6/ 0)    first  (6)\n",
    "# 4.93   12  (12/ 0)    second (6)\n",
    "# 5.00   18  (12/ 6)                        first  (3) \n",
    "# 5.69   24  (18/ 6)    third  (6)\n",
    "# 5.75   30  (18/12)                        second (3) \n",
    "# 6.42   42  (18/24)                        third  (6) \n",
    "# 7.53   54  (30/24)    fourth (12) \n",
    "# 7.57   66  (30/36)                        fourth (6) \n",
    "# 8.09   72  (30/42)                        fifth  (3) \n",
    "# 8.53   78  (36/42)    fifth  (6)\n",
    "# 8.57   90  (36/54)                        sixth  (6) \n",
    "# 9.47   96  (36/60)                        seventh(3)\n",
    "# 9.58  102  (36/60/6)                                      first  (3)\n",
    "# 9.85  108  (42/60/6)  sixth  (6)          \n",
    "# 9.89  120  (42/72/6)                      eigth  (6)\n",
    "#10.00  126  (42/72/12)                                     second (3)\n",
    "#10.26  138  (54/72/12) seventh(12)\n",
    "#10.29  150  (54/84/12)                     ninth  (6)\n",
    "#10.39  162  (54/84/24)                                     third  (6)\n",
    "#11.10  174  (54/96/24)                     tenth(6)\n",
    "#11.14  186  (54/96/36)                                     fourth(6)\n",
    "#11.38  192  (60/96/36) eighth(6)\n",
    "#11.50  198  (60/96/42)                                     fifth(3)\n",
    "#11.76  210  (60/108/42)                    ninth(6)\n",
    "#11.84  222  (60/108/54)                                    sixth(6)\n",
    "#12.40  234  (72/108/54) ninth(12)\n",
    "#12.42  252  (72/126/54)                    tenth(9)\n",
    "#12.51  258  (72/126/60)                                    seventh(3)\n",
    "#12.75  270  (72/138/60)                    eleventh(6)\n",
    "#12.83  282  (72/138/72)                                    eighth(6)\n",
    "#13.03  294  (84/138/72) tenth(12)\n",
    "#13.14  306  (84/138/84)                                    ninth(6)\n",
    "#13.66  318  (84/150/84)                    twelfth(6)\n",
    "#13.74  330  (84/150/96)                                    tenth(6)\n",
    "#13.96  336  (84/156/96)                    thiteenth(3)\n",
    "#14.15  338  (84/156/96/2)                                                  first(1)\n",
    "#bis 12 bleiben es 222 nachbarn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eb6a5375e38cbe1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### triplet cutoff",
   "id": "39ea2be6635ef020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read results cutoff2\n",
    "\n",
    "best_cutoffs2 = {}\n",
    "df2 = {}\n",
    "\n",
    "for fit_method in fit_methods:\n",
    "    df2[fit_method] = {'c2':[],'rmse_validation':[],'rmse_train':[],'BIC':[],'n_parameters':[],'n_nonzero_parameters':[]}\n",
    "file = open('/nfshome/winkelmann/ARL/save/cutoff_2_noTS_fitting_data','r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    df2[values[0]]['c2'].append(float(values[1]))\n",
    "    df2[values[0]]['rmse_validation'].append(float(values[2]))\n",
    "    df2[values[0]]['rmse_train'].append(float(values[3]))\n",
    "    df2[values[0]]['BIC'].append(float(values[4]))\n",
    "    df2[values[0]]['n_parameters'].append(float(values[5]))\n",
    "    df2[values[0]]['n_nonzero_parameters'].append(float(values[6]))\n",
    "\n",
    "for fit_method in fit_methods:\n",
    "    df2[fit_method] = pd.DataFrame(df2[fit_method])\n",
    "    best_cutoffs2[fit_method] = df2[fit_method].c2[df2[fit_method].rmse_validation.idxmin()]\n",
    "\n",
    "for key,cutoff in best_cutoffs2.items():\n",
    "    print(\"%s: %s\" %(key, cutoff))\n",
    "max_cutoff2 = max(best_cutoffs2.values())\n",
    "print('Max pair cutoff: %s' % max_cutoff2)"
   ],
   "id": "24fcb613de2e4dbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "jupyter_stop('dont rerun cutoff-3-scan if not necessary - needs some time')\n",
    "\n",
    "# c3_vals = c2_vals[0: biggest min(rmse_validation) cutoff2]\n",
    "# changed to 10 since everything above 8.09=c2_vals[9]\n",
    "c3_vals = c2_vals[:10]\n",
    "df3 = {}\n",
    "\n",
    "save_file = prevent_overwrite('/nfshome/winkelmann/ARL/tmp/cutoff_noTS_3_fit')\n",
    "file_format = '%14s,\\t%8s,\\t%15s,\\t%15s,\\t%15s,\\t%5s,\\t%5s' + os.linesep\n",
    "file = open(save_file,'w')\n",
    "file.write(file_format % ('fit_method', 'cutoff3', 'validation', 'train', 'BIC', 'number', 'nonzero'))\n",
    "file.close()\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method]= []\n",
    "    for c3 in c3_vals:     \n",
    "        cutoffs = [best_cutoffs2[fit_method], c3]\n",
    "        row = train_ce(prim=prim_without_TS,\n",
    "                       chemical_symbols=chemical_symbols_without_TS, \n",
    "                       cutoffs=cutoffs, \n",
    "                       energy_list = train_H_o_M, \n",
    "                       atoms_ref_list = train_structures,\n",
    "                       outcar_list = file_location, \n",
    "                       position_tolerance = position_tolerance, \n",
    "                       symprec = symprec, \n",
    "                       tol_positions = tol_positions, \n",
    "                       fit_method = fit_method)\n",
    "        records[fit_method].append({'c3': c3, **row})\n",
    "        \n",
    "        file = open(save_file,'a')\n",
    "        file.write(file_format % (fit_method, c3, row['rmse_validation'], row['rmse_train'], row['BIC'], row['n_parameters'], row['n_nonzero_parameters']))\n",
    "        file.close()\n",
    "    df3[fit_method]= pd.DataFrame(records[fit_method])\n",
    "print(save_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "388710ea5afd0916",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### quartett cutoff",
   "id": "e7bef34dd26d279f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read results cutoff3\n",
    "\n",
    "best_cutoffs3 = {}\n",
    "df3 = {}\n",
    "\n",
    "for fit_method in fit_methods:\n",
    "    df3[fit_method] = {'c3':[],'rmse_validation':[],'rmse_train':[],'BIC':[],'n_parameters':[],'n_nonzero_parameters':[]}\n",
    "file = open('/nfshome/winkelmann/ARL/save/cutoff_3_noTS_fitting_data','r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    if len(values) > 7:\n",
    "        print(values[7] + ',' + str(values[0:7]))\n",
    "        continue\n",
    "    df3[values[0]]['c3'].append(float(values[1]))\n",
    "    df3[values[0]]['rmse_validation'].append(float(values[2]))\n",
    "    df3[values[0]]['rmse_train'].append(float(values[3]))\n",
    "    df3[values[0]]['BIC'].append(float(values[4]))\n",
    "    df3[values[0]]['n_parameters'].append(float(values[5]))\n",
    "    df3[values[0]]['n_nonzero_parameters'].append(float(values[6]))\n",
    "\n",
    "for fit_method in fit_methods:\n",
    "    df3[fit_method] = pd.DataFrame(df3[fit_method])\n",
    "    best_cutoffs3[fit_method] = df3[fit_method].c3[df3[fit_method].rmse_validation.idxmin()]\n",
    "\n",
    "for key,cutoff in best_cutoffs3.items():\n",
    "    print(\"%s: %s\" %(key, cutoff))\n",
    "max_cutoff3 = max(best_cutoffs3.values())\n",
    "print('Max triplet cutoff: %s' % max_cutoff3)"
   ],
   "id": "46950913539157",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# c4_vals = c2_vals[0: biggest min(rmse_validation) cutoff3]\n",
    "jupyter_stop('dont rerun cutoff-4-scan if not necessary - needs some time')\n",
    "\n",
    "c4_vals = c2_vals[:c2_vals.index(max_cutoff3)+3]\n",
    "df4 = {}\n",
    "\n",
    "save_file = prevent_overwrite('/nfshome/winkelmann/ARL/tmp/cutoff_4_noTS_fit')\n",
    "file_format = '%14s,\\t%8s,\\t%15s,\\t%15s,\\t%15s,\\t%5s,\\t%5s' + os.linesep\n",
    "file = open(save_file,'w')\n",
    "file.write(file_format % ('fit_method', 'cutoff4', 'validation', 'train', 'BIC', 'number', 'nonzero'))\n",
    "file.close()\n",
    "for fit_method in fit_methods:\n",
    "    records[fit_method]= []\n",
    "    for c4 in c4_vals:       \n",
    "        cutoffs = [best_cutoffs2[fit_method], best_cutoffs3[fit_method], c4]\n",
    "        row = train_ce(prim=prim_without_TS,\n",
    "                       chemical_symbols=chemical_symbols_without_TS, \n",
    "                       cutoffs=cutoffs, \n",
    "                       energy_list = train_H_o_M, \n",
    "                       atoms_ref_list = train_structures,\n",
    "                       outcar_list = file_location, \n",
    "                       position_tolerance = position_tolerance, \n",
    "                       symprec = symprec, \n",
    "                       tol_positions = tol_positions, \n",
    "                       fit_method = fit_method)\n",
    "        records[fit_method].append({'c4': c4, **row})\n",
    "        \n",
    "        file = open(save_file,'a')\n",
    "        file.write(file_format % (fit_method, c4, row['rmse_validation'], row['rmse_train'], row['BIC'], row['n_parameters'], row['n_nonzero_parameters']))\n",
    "        file.close()\n",
    "    df4[fit_method]= pd.DataFrame(records[fit_method])\n",
    "print(save_file)"
   ],
   "id": "f77497275cd99538",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read results cutoff4\n",
    "\n",
    "best_cutoffs4 = {}\n",
    "df4 = {}\n",
    "\n",
    "for fit_method in fit_methods:\n",
    "    df4[fit_method] = {'c4':[],'rmse_validation':[],'rmse_train':[],'BIC':[],'n_parameters':[],'n_nonzero_parameters':[]}\n",
    "file = open('/nfshome/winkelmann/ARL/save/cutoff_4_noTS_fitting_data','r')\n",
    "file.readline()\n",
    "lines = file.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    line = line.replace(' ', '')\n",
    "    values = line.split(',')\n",
    "    if len(values) > 7:\n",
    "        print(values[7] + ',' + str(values[0:7]))\n",
    "        continue\n",
    "    df4[values[0]]['c4'].append(float(values[1]))\n",
    "    df4[values[0]]['rmse_validation'].append(float(values[2]))\n",
    "    df4[values[0]]['rmse_train'].append(float(values[3]))\n",
    "    df4[values[0]]['BIC'].append(float(values[4]))\n",
    "    df4[values[0]]['n_parameters'].append(float(values[5]))\n",
    "    df4[values[0]]['n_nonzero_parameters'].append(float(values[6]))\n",
    "\n",
    "for fit_method in fit_methods:\n",
    "    df4[fit_method] = pd.DataFrame(df4[fit_method])\n",
    "    best_cutoffs4[fit_method] = df4[fit_method].c4[df4[fit_method].rmse_validation.idxmin()]\n",
    "\n",
    "for key,cutoff in best_cutoffs4.items():\n",
    "    print(\"%s: %s\" %(key, cutoff))"
   ],
   "id": "536726b18fd54b8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#write cutoff file\n",
    "\n",
    "save_file = prevent_overwrite('/nfshome/winkelmann/ARL/tmp/best_cutoffs_noTS')\n",
    "file_format = '%14s,\\t%8s,\\t%8s,\\t%8s' + os.linesep\n",
    "file = open(save_file,'w')\n",
    "file.write(file_format % ('fit_method', 'cutoff2', 'cutoff3', 'cutoff4'))\n",
    "for fit_method in fit_methods:\n",
    "    file.write(file_format % (fit_method, best_cutoffs2[fit_method], best_cutoffs3[fit_method], best_cutoffs4[fit_method]))\n",
    "file.close()\n"
   ],
   "id": "ad987170fa8a4a6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## comparing fitting algorithms"
   ],
   "metadata": {},
   "id": "bf695c42566b9bd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Store stuff for use later\n",
    "data = {'concentration': [], 'reference_energy': [], 'predicted_energy': [], 'file_location': []}\n",
    "\n",
    "# Go trough all the data\n",
    "for outcar, mapped_structure, h_o_m, location in zip(file_location, mapped_structures_without_TS, train_H_o_M, file_location):\n",
    "    \n",
    "    try:\n",
    "        # Compute Li concentration\n",
    "        data['concentration'].append(mapped_structure.get_chemical_symbols().count(\"Li\")/(mapped_structure.get_chemical_symbols().count(\"O\")/2))\n",
    "\n",
    "        # Add original energy to dictthe factor of 1e3 serves to convert from eV/atom to meV/atom\n",
    "        data['reference_energy'].append(1e3 * h_o_m)\n",
    "        \n",
    "        # keep the file location to allow parsing\n",
    "        data['file_location'].append(location)\n",
    "    \n",
    "    # Catch errors in case something goes wrong\n",
    "    except Exception as err:\n",
    "        print(f\"Problems with {outcar}\")\n",
    "        print(f\"Original Error Message:\\n {err}\\n\")"
   ],
   "id": "203e4b186f356a9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up Clusterspace\n",
    "cs = ClusterSpace(structure=prim_without_TS,\n",
    "                      cutoffs=cutoffs,\n",
    "                      chemical_symbols=chemical_symbols_without_TS,\n",
    "                      position_tolerance=position_tolerance,\n",
    "                      symprec=symprec)    "
   ],
   "id": "c559588f-5153-4193-9898-421610b2d239",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import time as pytime\n",
    "comp_time = {}\n",
    "ce_fittings = {}\n",
    "rmse = {}"
   ],
   "metadata": {},
   "id": "740884d71107aa3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan ardr_lambda\n",
    "start_time = pytime.time()\n",
    "lambda_values = 1000 #factor for standard deviation?\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='ardr', threshold_lambda=lambda_values)\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_ardr_lambda = pd.DataFrame([records])\n",
    "print(records)\n",
    "rmse['ardr_lambda'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_ardr_lambda = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_ardr_lambda.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_ardr_lambda.ce')\n",
    "ce_fittings['ardr_lambda'] = ce_ardr_lambda\n",
    "comp_time['ardr_lambda'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "faa996675f049069",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan ARDR_lineScan\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='ardr', line_scan=True)\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_ardr_lineScan = pd.DataFrame([records])\n",
    "print(records)\n",
    "rmse['ardr_lineScan'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_ardr_lineScan = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_ardr_lineScan.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_ardr_lineScan.ce')\n",
    "ce_fittings['ardr_lineScan'] = ce_ardr_lineScan\n",
    "comp_time['ardr_lineScan'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "bd8429ff7283b0e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan rfe\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='rfe')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_rfe = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['rfe'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_rfe = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_rfe.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_rfe.ce')\n",
    "ce_fittings['rfe'] = ce_rfe\n",
    "comp_time['rfe'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "47ee09d97d7ec647",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan lasso\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='lasso')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_lasso = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['lasso'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_lasso = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_lasso.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_lasso.ce')\n",
    "ce_fittings['lasso'] = ce_lasso\n",
    "comp_time['lasso'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "bd3c2964fc365976",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan least_squares\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='least-squares')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_least_squares = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['least_squares'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_least_squares = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_least_squares.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_least_squares.ce')\n",
    "ce_fittings['least_squares'] = ce_least_squares\n",
    "comp_time['least_squares'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "637ed3d91a67ede6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan bayesian_ridge\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='bayesian-ridge')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_bayesian_ridge = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['bayesian_ridge'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_bayesian_ridge = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_bayesian_ridge.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_bayesian_ridge.ce')\n",
    "ce_fittings['bayesian_ridge'] = ce_bayesian_ridge\n",
    "comp_time['bayesian_ridge'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "fea6e672fc423ff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan elasticnet\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='elasticnet')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_elasticnet = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['elasticnet'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_elasticnet = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_elasticnet.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_elasticnet.ce')\n",
    "ce_fittings['elasticnet'] = ce_elasticnet\n",
    "comp_time['elasticnet'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "c2385e566bb83195",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan omp\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='omp')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_omp = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['omp'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_omp  = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_omp.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_omp.ce')\n",
    "ce_fittings['omp'] = ce_omp\n",
    "comp_time['omp'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "98a9cb92b37343f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan ridge \n",
    "# how ridge regression without regularization parameters\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='ridge')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_ridge = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['ridge'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_ridge  = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_ridge.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_ridge.ce')\n",
    "ce_fittings['ridge'] = ce_ridge\n",
    "comp_time['ridge'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "7b0b1772ffd75a0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# scan split_bregman\n",
    "start_time = pytime.time()\n",
    "cve = CrossValidationEstimator((A_without_TS, y_without_TS), fit_method='split-bregman')\n",
    "cve.validate()\n",
    "cve.train()\n",
    "records = get_row(cve)\n",
    "print(pd.DataFrame([records]))\n",
    "df_split_bregman = pd.DataFrame([records]) # strange error when not giving a list\n",
    "print(records)\n",
    "rmse['split_bregman'] = {'validation':records['rmse_validation'], 'train':records['rmse_train']}\n",
    "\n",
    "ce_split_bregman = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "ce_split_bregman.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_split_bregman.ce')\n",
    "ce_fittings['split_bregman'] = ce_split_bregman\n",
    "comp_time['split_bregman'] = pytime.time() - start_time"
   ],
   "metadata": {},
   "id": "5e7062ca83f39f2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## plotting and comparing results"
   ],
   "metadata": {},
   "id": "b78e411ea4e35c92"
  },
  {
   "cell_type": "code",
   "source": [
    "#adding data to compare Optimization\n",
    "data_predict_opt = {}\n",
    "for key,value in comp_time.items():\n",
    "    data_predict_opt[key] = []    \n",
    "    for outcar, mapped_structure, h_o_m, location in zip(file_location, mapped_structures_without_TS, train_H_o_M, file_location):\n",
    "        # use the mapped structures to predict energy\n",
    "        data_predict_opt[key].append(1e3 * ce_fittings[key].predict(mapped_structure))"
   ],
   "metadata": {},
   "id": "217beebd1ac7909c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#calculating diffrence of methods from training data and to convexhull\n",
    "from icet.tools import ConvexHull\n",
    "import os\n",
    "\n",
    "hull = ConvexHull(data['concentration'], data['reference_energy'])\n",
    "data['hull_energy'] = []\n",
    "for concentration in data['concentration']:\n",
    "    data['hull_energy'].append(hull.get_energy_at_convex_hull(concentration))\n",
    "file = open('/nfshome/winkelmann/ARL/tmp/comparing_optimization', 'a') \n",
    "\n",
    "\n",
    "#calculating distance to hull \n",
    "hull_distances = {}\n",
    "for key,value in data_predict_opt.items():\n",
    "    hull_distances[key] = np.absolute(np.subtract(data['hull_energy'], value))\n",
    "    write_string = '%14s \\t RMSE validation: %22s \\t train: %22s \\t hull: %s \\t time: %s' %(key, rmse[key]['validation'], rmse[key]['train'], sum(hull_distance), comp_time[key])\n",
    "    file.write(write_string + os.linesep)\n",
    "    print(write_string)\n",
    "file.close()"
   ],
   "metadata": {},
   "id": "4dce7ade7e822b2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sorted_concentration_indices = np.argsort(data['concentration'])\n",
    "pdf = PdfPages('/nfshome/winkelmann/ARL/tmp/comparing_optimization.pdf')\n",
    "\n",
    "for key, value in data_predict_opt.items():\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,9))\n",
    "\n",
    "    # ax1 = HOM (predict & reference) & hull\n",
    "\n",
    "    ax1.set_title('heat of mixing (%s)' % key)\n",
    "    ax1.set_xlabel('x in Li$_x$')\n",
    "    ax1.set_ylabel('Mixing energy (meV/atom)')\n",
    "\n",
    "    ax1.plot(np.array(data['concentration'])[sorted_concentration_indices],\n",
    "             np.array(hull_energy)[sorted_concentration_indices], label='convex hull of reference')\n",
    "    ax1.scatter(data['concentration'], data['reference_energy'], marker='o', label='reference')\n",
    "    ax1.scatter(data['concentration'], value, marker='x', label=key)\n",
    "    \n",
    "    \n",
    "    # ax2 = reference vs predict (color coded for diffrence hull\n",
    "\n",
    "    ax2.set_title('prediction error plot (%s)' % key)\n",
    "    ax2.set_xlabel('Prediction (mev/atom)')\n",
    "    ax2.set_ylabel('reference (meV/atom)')\n",
    "    \n",
    "    img = ax2.scatter(data['reference_energy'], value, c=hull_distances[key], cmap='coolwarm')\n",
    "    cb = fig.colorbar(img)\n",
    "    cb.set_label('distance to hull (predicted)')\n",
    "    ax2.plot(ax2.get_xlim(), ax2.get_ylim(), ls='--', color='black')  # plotting a diagonal line for reference\n",
    "    pdf.savefig(figure=fig, bbox_inches='tight')\n",
    "pdf.close()"
   ],
   "metadata": {},
   "id": "f68eea26f6ccc340",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## via Convex Hull"
   ],
   "metadata": {},
   "id": "bad29bc94c8c0a9d"
  },
  {
   "cell_type": "code",
   "source": [
    "# optimizing CE\n",
    "from icet.tools import ConvexHull\n",
    "from trainstation import Optimizer\n",
    "\n",
    "cluster_vectors = A_without_TS.copy()\n",
    "data_opt = data.copy()\n",
    "data_opt['predicted_energy'] = []\n",
    "hull = ConvexHull(data['concentration'], data['reference_energy'])\n",
    "weight = np.ones(len(data_opt['concentration']))\n",
    "\n",
    "n = 0\n",
    "#calculating weighting factor - by distance to convex hull\n",
    "for distance in deviations):\n",
    "    hull_energy = hull.get_energy_at_convex_hull(data_opt['concentration'][i])\n",
    "    deviation = abs(data_opt['reference_energy'][i] - hull_energy)\n",
    "    if deviation != 0:\n",
    "        weight[i] = 1/deviation\n",
    "    else:\n",
    "        weight[i] = 0 #number makes no noticable diffrence (weights should be small but this should be the highest)\n",
    "max_weight = weight.max()\n",
    "for w in weight:\n",
    "    if w == 0:\n",
    "        w = max_weight * 1.1\n",
    "#calculate weighted ClusterVectors and energies\n",
    "cluster_vectors_weighted = np.multiply(cluster_vectors, weight.reshape(-1, 1))\n",
    "reference_energy_weighted = np.multiply(y_without_TS, weight)\n",
    "opt = Optimizer((cluster_vectors_weighted, reference_energy_weighted), fit_method='ridge')\n",
    "opt.train()\n",
    "\n",
    "#create optimized CE from it\n",
    "ce_opt = ClusterExpansion(cluster_space=cs, parameters=opt.parameters, metadata=opt.summary)\n",
    "ce.write('/nfshome/winkelmann/ARL/tmp/mixing_energy_no_TS_opt_convexHull.ce')"
   ],
   "metadata": {},
   "id": "32e52e40ddf4f802",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#adding data to compare Optimization\n",
    "for outcar, mapped_structure, h_o_m, location in zip(file_location, mapped_structures_without_TS, train_H_o_M, file_location):\n",
    "    # use the mapped structures to predict energy\n",
    "    data_opt['predicted_energy'].append(1e3 * ce_opt.predict(mapped_structure))"
   ],
   "metadata": {},
   "id": "f02b8f217b2a7d30",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#plotting opt CE against training Data and not optized CE\n",
    "\n",
    "fig, ((ax5, ax6), (ax7, ax8)) = plt.subplots(2, 2, figsize=(18, 18))\n",
    "\n",
    "hull_energy = []\n",
    "for concentration in data['concentration']:\n",
    "    hull_energy.append(hull.get_energy_at_convex_hull(concentration))\n",
    "sorted_concentration_indices = np.argsort(data['concentration'])\n",
    "\n",
    "## ax6 = Optimised vs. training Data\n",
    "ax5.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax5.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax5.set_xlim([0, 1])\n",
    "ax5.set_ylim([-40, 30])\n",
    "ax5.scatter(data['concentration'], data['reference_energy'],\n",
    "            marker='o', color='blue', label='reference')\n",
    "ax5.scatter(data_opt['concentration'], data_opt['predicted_energy'],\n",
    "            marker='+', color='green', label='CE_opt prediction')\n",
    "ax5.legend()\n",
    "ax5.set_title(\"Optimised vs. training Data\")\n",
    "\n",
    "## ax6 = Optimised vs. unoptimized\n",
    "ax6.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax6.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax6.set_xlim([0, 1])\n",
    "ax6.set_ylim([-40, 30])\n",
    "ax6.scatter(data['concentration'], data['predicted_energy'],\n",
    "            marker='x', color='orange', label='CE prediction')\n",
    "ax6.scatter(data_opt['concentration'], data_opt['predicted_energy'],\n",
    "            marker='+', color='green', label='CE_opt prediction')\n",
    "\n",
    "ax6.legend()\n",
    "ax6.set_title(\"Optimised vs. unoptimized\")\n",
    "\n",
    "## ax7 = Optimised vs. convex_Hull\n",
    "ax7.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax7.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax7.set_xlim([0, 1])\n",
    "ax7.set_ylim([-40, 30])\n",
    "ax7.plot(np.array(data['concentration'])[sorted_concentration_indices],np.array(hull_energy)[sorted_concentration_indices])\n",
    "#ax7.plot(data['concentration'][sorted_concentration_indices], hull_energy[sorted_concentration_indices],\n",
    "#            marker='.', color='grey', label='Convex_Hull')\n",
    "ax7.scatter(data_opt['concentration'], data_opt['predicted_energy'],\n",
    "            marker='+', color='green', label='CE_opt prediction')\n",
    "ax7.legend()\n",
    "ax7.set_title(\"Optimised vs. convex_Hull\")\n",
    "\n",
    "##ax8 = Full heat of mixing plot comparison\n",
    "ax8.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax8.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax8.set_xlim([0, 1])\n",
    "ax8.set_ylim([-40, 30])\n",
    "ax8.scatter(data['concentration'], data['reference_energy'],\n",
    "            marker='o', color='blue', label='reference')\n",
    "ax8.scatter(data['concentration'], data['predicted_energy'],\n",
    "            marker='x', color='orange', label='CE prediction')\n",
    "ax8.scatter(data_opt['concentration'], data_opt['predicted_energy'],\n",
    "            marker='+', color='green', label='CE_opt prediction')\n",
    "ax8.plot(np.array(data['concentration'])[sorted_concentration_indices],np.array(hull_energy)[sorted_concentration_indices])\n",
    "ax8.legend()\n",
    "ax8.set_title(\"Full CE plot - comparison\")\n",
    "\n",
    "plt.savefig('/nfshome/winkelmann/ARL/tmp/optimization_comparison_no_TS_opt_convexHull.png',\n",
    "            bbox_inches='tight')"
   ],
   "metadata": {},
   "id": "4420f98351adb65a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# First fitting for testing purposes of python implementation (no Ni_Li, but with transition states)"
   ],
   "id": "ab7af853-95ad-4deb-9ce3-aae494c19b1f"
  },
  {
   "cell_type": "code",
   "source": [
    "# combine the structures \n",
    "train_structures.append(atoms_for_training_NEB_transition_states) \n",
    "\n",
    "# ... and energies\n",
    "train_H_o_M.append(H_o_M_for_training_NEB_transition_states)\n",
    "\n",
    "# to be able to retrieve problematic files, keep the paths\n",
    "file_location.append(paths_for_training_NEB_transition_states)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8a00d3da43f558a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3cdaf2a5-1537-452a-a989-7d8c394f258c",
   "metadata": {},
   "source": [
    "# Assign chemical symbols\n",
    "chemical_symbols= [['Li', 'X'],   # Li sublattice will contain: Li and Vacancies (=X), later also Ni\n",
    "                    ['Ni'],       # Ni sublattice will not be changed\n",
    "                    ['O'],        # O  sublattice will not be changed\n",
    "                    ['O'],\n",
    "                    ['Li','X'],   # Transition state sites\n",
    "                    ['Li','X'],\n",
    "                    ['Li','X'],]        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79b0faea-a3da-4247-91ec-fe8b325dd214",
   "metadata": {},
   "source": [
    "# get the fitting data\n",
    "cutoffs = [8.57, 7.53, 6.42]\n",
    "position_tolerance = 0.01\n",
    "symprec = 0.01\n",
    "tol_positions=0.05\n",
    "\n",
    "(A, y), mapped_structures = get_A_y(prim=prim, \n",
    "                                   chemical_symbols=chemical_symbols, \n",
    "                                   cutoffs=cutoffs,                \n",
    "                                   energy_list = train_H_o_M, \n",
    "                                   atoms_ref_list = train_structures, \n",
    "                                   outcar_list = file_location,\n",
    "                                   position_tolerance=position_tolerance,\n",
    "                                   symprec=symprec,\n",
    "                                   tol_positions=tol_positions)\n",
    "\n",
    "# Markus:  8.5966 Å, 8.1068 Å and 6.4169 Å\n",
    "\n",
    "# Concerning pair cutoff within one Li layer\n",
    "# Neighbor       distance           how many within layer      summed total per particle\n",
    "#                                                               including Li layers above/below\n",
    "# 1st neighbor at 2.8429                N= 6                         N =  6 (only intralayer bonds)\n",
    "# 2nd neighbor at 4.92404               N= 6                         N = 12 (only intralayer bonds)\n",
    "# 3rd neighbor at 5.68579 (=2*2.8429)   N= 6                         N = 24 (first bonds to other layers. 3 bonds to layer above and 3 to layer below)  \n",
    "# 4th neighber at 7.5216                N=12                         N = 54 \n",
    "# 5th neighbor at 8.52869 (=3*2.8429)   N= 6                         N = 78 \n",
    "\n",
    "# Note: 4th cutoff here is just slightly smaller than 4th interlayer cutoff.\n",
    "# Note: 5th cutoff here is just slightly smaller than 6th interlayer cutoff.\n",
    "\n",
    "\n",
    "# Concerning cutoff for interlayer bonds:\n",
    "# 1st interlayerbonds     at  4.99272   N= 3 (to both above and below)   Total interlayer summed up= 6\n",
    "# 2nd interlayerbonds     at  5.74537   N= 3 (to both above and below)   Total interlayer summed up= 12\n",
    "# 3rd interlayerbonds     at  6.41025   N= 6 (to both above and below)   Total interlayer summed up= 24\n",
    "# 4th interlayerbonds     at  7.56673   N= 6 (to both above and below)   Total interlayer summed up= 36\n",
    "# 5th interlayerbonds     at  8.08316   N= 3 (to both above and below)   Total interlayer summed up= 42\n",
    "# 6th interlayerbonds     at  8.56852   N= 6 (to both above and below)   Total interlayer summed up= 54\n",
    "\n",
    "#Total number of Li-Li Bonds as function of cutoff (inter/intra):\n",
    "# 2.84    0  ( 0/ 0)\n",
    "# 2.85    6  ( 6/ 0)\n",
    "# 4.93   12  (12/ 0)\n",
    "# 5.00   18  (12/ 6)\n",
    "# 5.69   24  (18/ 6)\n",
    "# 5.75   30  (18/12)  \n",
    "# 6.42   42  (18/24)  3rd    3rd\n",
    "# 7.53   54  (30/24)  2nd\n",
    "# 7.57   66  (30/36)\n",
    "# 8.09   72  (30/42)         2nd\n",
    "# 8.53   78  (36/42)\n",
    "# 8.57   90  (36/54)  1st    1st\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6476a351-1624-4b74-a482-0333be8edb99",
   "metadata": {},
   "source": [
    "# scan ARDR\n",
    "lambda_values = [1000]\n",
    "records = []\n",
    "for lam in lambda_values:\n",
    "    cve = CrossValidationEstimator((A, y), fit_method='ardr', threshold_lambda=lam)\n",
    "    cve.validate()\n",
    "    cve.train()\n",
    "    row = get_row(cve)\n",
    "    row['threshold_lambda'] = lam\n",
    "    records.append(row)\n",
    "df_ardr = pd.DataFrame(records)\n",
    "print(row)\n",
    "\n",
    "# Set up Clusterspace\n",
    "cs = ClusterSpace(structure=prim,\n",
    "                      cutoffs=cutoffs,\n",
    "                      chemical_symbols=chemical_symbols,\n",
    "                      position_tolerance=position_tolerance,\n",
    "                      symprec=symprec)\n",
    "\n",
    "\n",
    "ce = ClusterExpansion(cluster_space=cs, parameters=cve.parameters, metadata=cve.summary)\n",
    "print(ce)\n",
    "ce.write('/nfshome/winkelmann/ARL/tmp/mixing_energy.ce')\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "715c9f87-0e34-4e02-b981-e1caedf4d77b",
   "metadata": {},
   "source": [
    "# Read the previously outputted CE and set up a dictionary with data to be plotted later\n",
    "ce = ClusterExpansion.read('/nfshome/winkelmann/ARL/tmp/mixing_energy.ce')\n",
    "write_vasp(\"/nfshome/winkelmann/ARL/tmp/real_prim.vasp\", ce.primitive_structure)\n",
    "\n",
    "# Store stuff for use later\n",
    "data = {'concentration': [], 'reference_energy': [], 'predicted_energy': [], 'file_location': []}\n",
    "\n",
    "# Go trough all the data\n",
    "for outcar, mapped_structure, h_o_m, location in zip(file_location, mapped_structures, train_H_o_M, file_location):\n",
    "    \n",
    "    try:\n",
    "        # Compute Li concentration\n",
    "        data['concentration'].append(mapped_structure.get_chemical_symbols().count(\"Li\")/(mapped_structure.get_chemical_symbols().count(\"O\")/2))\n",
    "\n",
    "        # Add original energy to dictthe factor of 1e3 serves to convert from eV/atom to meV/atom\n",
    "        data['reference_energy'].append(1e3 * h_o_m)\n",
    "\n",
    "        # use the mapped structures to predict energy\n",
    "        data['predicted_energy'].append(1e3 * ce.predict(mapped_structure))\n",
    "        \n",
    "        # keep the file location to allow parsing\n",
    "        data['file_location'].append(location)\n",
    "    \n",
    "    # Catch errors in case something goes wrong\n",
    "    except Exception as err:\n",
    "        print(f\"Problems with {outcar}\")\n",
    "        print(f\"Original Error Message:\\n {err}\\n\")\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99b566bd-049d-4b52-b12a-c01a1dd7ada1",
   "metadata": {},
   "source": [
    "# Retrieve the energy barriers and the corresponding predictons\n",
    "barrier_concentrations  = []\n",
    "ref_frontjump_barriers  = []\n",
    "ref_backjump_barriers   = []\n",
    "pred_frontjump_barriers = []\n",
    "pred_backjump_barriers  = []\n",
    "\n",
    "# Iterate over all run_final folders\n",
    "for path in paths_for_training_NEB_transition_states:\n",
    "        \n",
    "    # Check the energy along the path. Use initial and final energies from the corresponding relaxed structures + the last steps of the \n",
    "    # optimized intermediate images\n",
    "    energies = []\n",
    "    initial_image = ASEread(path.replace(\"run_final\", \"OUTCAR_initial_image\"))\n",
    "    energies.append(initial_image.get_potential_energy())\n",
    "    for i in [\"01\", \"02\", \"03\", \"04\", \"05\"]:\n",
    "        energies.append(ASEread(f\"{path}/{i}/OUTCAR\").get_potential_energy())\n",
    "    final_image = ASEread(path.replace(\"run_final\", \"OUTCAR_final_image\"))\n",
    "    energies.append(final_image.get_potential_energy())\n",
    "    \n",
    "    # For \"Proper\" paths, there should be maximum in energy !between! initial and final paths... ignore those where this is not the case\n",
    "    index_highest_energy = energies.index(max(energies))\n",
    "    \n",
    "    if index_highest_energy == 0 or index_highest_energy == 6:\n",
    "        print(f\"Ignore {path}\\n  ---> image {index_highest_energy} has highest energy!\")\n",
    "    \n",
    "    else:\n",
    "        # Compute reference frontjump and backjump barrier\n",
    "        ref_frontjump_barriers.append(max(energies) - energies[0])\n",
    "        ref_backjump_barriers.append(max(energies) - energies[-1])\n",
    "        \n",
    "        # Compute the predicted barriers...\n",
    "        # get the interpolated middle points of the initially created, straight odh-type path to be used as ideal position for the CE training\n",
    "        ideal_TS_structure_file = glob.glob(path.replace(\"run_final\", \"run01*/03/POSCAR_orig_linear_interpolation\"))\n",
    "        if len(ideal_TS_structure_file) == 0:                # For ODH-type jumps there is no POSCAR_orig_linear_interpolation\n",
    "            ideal_TS_structure_file = glob.glob(path.replace(\"run_final\", \"run01*/03/POSCAR\"))\n",
    "        ideal_TS_atoms = ASEread(ideal_TS_structure_file[0])\n",
    "        \n",
    "        # Map the initial, final and TS state:        \n",
    "        initial_mapped_atoms, info = icet.tools.map_structure_to_reference(structure=initial_image, \n",
    "                                                             reference=prim, \n",
    "                                                             inert_species=[\"O\"], \n",
    "                                                             tol_positions=0.05, \n",
    "                                                             suppress_warnings=False, \n",
    "                                                             assume_no_cell_relaxation=False)\n",
    "                          \n",
    "        final_mapped_atoms,   info = icet.tools.map_structure_to_reference(structure=final_image, \n",
    "                                                             reference=prim, \n",
    "                                                             inert_species=[\"O\"], \n",
    "                                                             tol_positions=0.05, \n",
    "                                                             suppress_warnings=False, \n",
    "                                                             assume_no_cell_relaxation=False)\n",
    "        \n",
    "        TS_mapped_atoms, info = icet.tools.map_structure_to_reference(structure=ideal_TS_atoms, \n",
    "                                                             reference=prim, \n",
    "                                                             inert_species=[\"O\"], \n",
    "                                                             tol_positions=0.05, \n",
    "                                                             suppress_warnings=False, \n",
    "                                                             assume_no_cell_relaxation=False)\n",
    "        \n",
    "        # Fromt their predicted <<<heat of mixing>>>, get the energies and from those get the barriers:\n",
    "        N_atoms = len(ideal_TS_atoms)\n",
    "        Li_count = ideal_TS_atoms.get_chemical_symbols().count(\"Li\")\n",
    "        O_count  = ideal_TS_atoms.get_chemical_symbols().count(\"O\")\n",
    "                          \n",
    "        pred_E_init  = ce.predict(initial_mapped_atoms) * N_atoms + Li_count * E_ref_LiNiO2_per_O2 + (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "        pred_E_final = ce.predict(final_mapped_atoms)   * N_atoms + Li_count * E_ref_LiNiO2_per_O2 + (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "        pred_E_TS    = ce.predict(TS_mapped_atoms)      * N_atoms + Li_count * E_ref_LiNiO2_per_O2 + (O_count/2-Li_count) * E_ref_NiO2_per_O2\n",
    "                        \n",
    "        pred_frontjump_barriers.append(pred_E_TS - pred_E_init)\n",
    "        pred_backjump_barriers.append( pred_E_TS - pred_E_final)                  \n",
    "                        \n",
    "        barrier_concentrations.append(Li_count/(O_count/2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d4de232-a725-4909-81b9-0ec5ab64f1dc",
   "metadata": {},
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3,2, figsize=(18, 25))\n",
    "\n",
    "### ax1 = Full heat of mixing plot\n",
    "\n",
    "ax1.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax1.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax1.set_xlim([0, 1])\n",
    "ax1.set_ylim([-40, 30])\n",
    "\n",
    "ax1.scatter(data['concentration'], data['reference_energy'],\n",
    "           marker='o', label='reference')\n",
    "ax1.scatter(data['concentration'], data['predicted_energy'],\n",
    "           marker='x', label='CE prediction')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Full CE plot\")\n",
    "\n",
    "\n",
    "\n",
    "### ax2 = Heat of mixing plot of my own structures\n",
    "\n",
    "ax2.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax2.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.set_ylim([-40, 30])\n",
    "\n",
    "# Take only the ones we are interested here\n",
    "concentration    = []\n",
    "reference_energy = []\n",
    "predicted_energy = []\n",
    "\n",
    "for c, ref , pred, location in zip(data[\"concentration\"], data[\"reference_energy\"], data[\"predicted_energy\"], data[\"file_location\"]):\n",
    "    if \"02_enumerate_P21c_0-4fu\" in location:\n",
    "        concentration.append(c)\n",
    "        reference_energy.append(ref)\n",
    "        predicted_energy.append(pred)\n",
    "\n",
    "ax2.scatter(concentration, reference_energy,\n",
    "           marker='o', label='reference')\n",
    "ax2.scatter(concentration, predicted_energy,\n",
    "           marker='x', label='CE prediction')\n",
    "\n",
    "ax2.legend()\n",
    "ax2.set_title(\"Marcel's enumerated data\")\n",
    "\n",
    "\n",
    "\n",
    "### ax3 = Heat of mixing plot of Markus's re-relaxed_structures\n",
    "\n",
    "ax3.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax3.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([-40, 30])\n",
    "\n",
    "# Take only the ones we are interested here\n",
    "concentration    = []\n",
    "reference_energy = []\n",
    "predicted_energy = []\n",
    "\n",
    "for c, ref , pred, location in zip(data[\"concentration\"], data[\"reference_energy\"], data[\"predicted_energy\"], data[\"file_location\"]):\n",
    "    if \"re-relax_Markus\" in location:\n",
    "        concentration.append(c)\n",
    "        reference_energy.append(ref)\n",
    "        predicted_energy.append(pred)\n",
    "\n",
    "ax3.scatter(concentration, reference_energy,\n",
    "           marker='o', label='reference')\n",
    "ax3.scatter(concentration, predicted_energy,\n",
    "           marker='x', label='CE prediction')\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_title(\"Markus' re-relaxed structures\")\n",
    "\n",
    "\n",
    "\n",
    "### ax4 = Heat of mixing plot of the initial and final NEB images\n",
    "\n",
    "ax4.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax4.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax4.set_xlim([0, 1])\n",
    "ax4.set_ylim([-40, 30])\n",
    "\n",
    "# Take only the ones we are interested here\n",
    "concentration    = []\n",
    "reference_energy = []\n",
    "predicted_energy = []\n",
    "\n",
    "for c, ref , pred, location in zip(data[\"concentration\"], data[\"reference_energy\"], data[\"predicted_energy\"], data[\"file_location\"]):\n",
    "    if \"01_initial_structure\" in location \\\n",
    "    or \"02_odh/image\"         in location \\\n",
    "    or \"03_tsh/image\"         in location \\\n",
    "    or \"04_doube_tsh/image\"   in location \\\n",
    "    or \"0250/image\"           in location \\\n",
    "    or \"0500/image\"           in location \\\n",
    "    or \"0750/image\"           in location:\n",
    "        concentration.append(c)\n",
    "        reference_energy.append(ref)\n",
    "        predicted_energy.append(pred)\n",
    "\n",
    "ax4.scatter(concentration, reference_energy,\n",
    "           marker='o', label='reference')\n",
    "ax4.scatter(concentration, predicted_energy,\n",
    "           marker='x', label='CE prediction')\n",
    "\n",
    "ax4.legend()\n",
    "ax4.set_title(\"Initial and final NEB images\")\n",
    "\n",
    "\n",
    "\n",
    "### ax5 = Heat of mixing plot of the NEB transition states\n",
    "\n",
    "ax5.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax5.set_ylabel(r'Mixing energy (meV/atom)')\n",
    "ax5.set_xlim([0, 1])\n",
    "ax5.set_ylim([-40, 30])\n",
    "\n",
    "# Take only the ones we are interested here\n",
    "concentration    = []\n",
    "reference_energy = []\n",
    "predicted_energy = []\n",
    "\n",
    "for c, ref , pred, location in zip(data[\"concentration\"], data[\"reference_energy\"], data[\"predicted_energy\"], data[\"file_location\"]):\n",
    "    if \"/02_odh/NEB_\"          in location \\\n",
    "    or \"/03_tsh/NEB_\"          in location \\\n",
    "    or \"/04_double_tsh/NEB_\"   in location \\\n",
    "    or \"/0250/NEB_\"            in location \\\n",
    "    or \"/0500/NEB_\"            in location \\\n",
    "    or \"/0750/NEB_\"            in location:\n",
    "        concentration.append(c)\n",
    "        reference_energy.append(ref)\n",
    "        predicted_energy.append(pred)\n",
    "\n",
    "ax5.scatter(concentration, reference_energy,\n",
    "           marker='o', label='reference')\n",
    "ax5.scatter(concentration, predicted_energy,\n",
    "           marker='x', label='CE prediction')\n",
    "\n",
    "ax5.legend()\n",
    "ax5.set_title(\"NEB transition states\")\n",
    "\n",
    "\n",
    "\n",
    "### ax6 = Check the real barriers\n",
    "\n",
    "ax6.set_xlabel(r'x in Li$_x$NiO2')\n",
    "ax6.set_ylabel(r'Barriers in eV')\n",
    "ax6.set_xlim([0, 1])\n",
    "#ax6.set_ylim([-40, 30])\n",
    "\n",
    "# Front jump\n",
    "concentration    = []\n",
    "reference_energy = []\n",
    "predicted_energy = []\n",
    "for c, ref , pred, location in zip(barrier_concentrations, ref_frontjump_barriers, pred_frontjump_barriers, paths_for_training_NEB_transition_states):\n",
    "    concentration.append(c)\n",
    "    reference_energy.append(ref)\n",
    "    predicted_energy.append(pred)\n",
    "ax6.scatter(concentration, reference_energy,\n",
    "           marker='o', label='reference frontjump')\n",
    "ax6.scatter(concentration, predicted_energy,\n",
    "           marker='x', label='CE prediction frontjump')\n",
    "\n",
    "# Back jump\n",
    "concentration    = []\n",
    "reference_energy = []\n",
    "predicted_energy = []\n",
    "for c, ref , pred, location in zip(barrier_concentrations, ref_backjump_barriers, pred_backjump_barriers, paths_for_training_NEB_transition_states):\n",
    "    concentration.append(c)\n",
    "    reference_energy.append(ref)\n",
    "    predicted_energy.append(pred)\n",
    "ax6.scatter(concentration, reference_energy,\n",
    "           marker='o', label='reference backjump')\n",
    "ax6.scatter(concentration, predicted_energy,\n",
    "           marker='x', label='CE prediction backjump')\n",
    "\n",
    "\n",
    "ax6.legend()\n",
    "ax6.set_title(\"NEB transition states\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('/nfshome/winkelmann/ARL/tmp/mixing_energy_comparison.png', bbox_inches='tight')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9f8c40b-5715-4e61-b470-9090cd31a8c9",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.set_xlabel(r'reference heat of mixing [meV/atom]')\n",
    "ax.set_ylabel(r'predicted heat of mixing [meV/atom]')\n",
    "#ax.set_xlim([0, 1])\n",
    "#ax.set_ylim([-69, 15])\n",
    "ax.scatter(data['reference_energy'], data['predicted_energy'],\n",
    "           marker='o', label='reference')\n",
    "\n",
    "ax.plot(range(-30,30), range(-30,30), label='slope 1', color=\"red\")\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig('/nfshome/winkelmann/ARL/tmp/parity_plot.png', bbox_inches='tight')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa3d09d2-407b-491c-a912-a29ea1ea3ef3",
   "metadata": {},
   "source": [
    "#data['file_location']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37f707d7-a4e4-48fe-a902-6f274dd7b8f7",
   "metadata": {},
   "source": [
    "len(file_location)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "888919aa-7db7-4bd1-9d40-81743e2c0830",
   "metadata": {},
   "source": [
    "#READMEs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11fc332f-f060-49ba-8cdc-b7495ec740c3",
   "metadata": {},
   "source": [
    "\"/\".join([\"hello\",\"new\",\"world\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8771550-a215-416c-ba0f-7d2980394b9c",
   "metadata": {},
   "source": [
    "a = \"/hello/new/world\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6690608d-5f3a-48c6-9794-14faca5f866e",
   "metadata": {},
   "source": [
    "a.split(\"/\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6abdde42-7cea-41ab-b52d-d4165ed8ee9f",
   "metadata": {},
   "source": [
    "#paths_for_training_NEB_transition_states"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "996742c1-da24-4d50-8c4f-b749c0219448",
   "metadata": {},
   "source": [
    "#file_location"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71f66b52-1716-482e-af5f-c0a7f9c5fe6e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a6eeb21-d4de-43e4-afe6-45b3ad8bbcf4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e96e2d30-8ec8-48ad-8769-4efa2065e77a",
   "metadata": {},
   "source": [
    "data[\"file_location\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a8ca9f8-6f38-4316-9251-c6093156efb3",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
